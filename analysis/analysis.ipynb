{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from util import load_metric\n",
    "from scipy.stats import spearmanr, pearsonr, zscore, rankdata\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    return len(a.intersection(b)) / len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_show(df, var, k = 40, as_table = False, transition=True, min_freq=None, return_md=False):\n",
    "    \"\"\"\n",
    "    Given a dataframe, shows the top k words for variable var each year.\n",
    "    Note: as_table only sypported for transition variables!\n",
    "    \"\"\"\n",
    "    \n",
    "    COLUMNS = [col for col in sorted(df.columns) if col.startswith(var)]\n",
    "\n",
    "    if min_freq == None:    \n",
    "        WORDS = [df[col].sort_values(ascending=False)[:k].index for col in COLUMNS]\n",
    "    else:\n",
    "        TRANSITIONS = [tuple(col.split(\"_\")[-1].split(\":\")) for col in COLUMNS]\n",
    "        WORDS = [df[(df[f\"frq_{trs[0]}\"] >= min_freq) & (df[f\"frq_{trs[1]}\"] >= min_freq)][col].sort_values(ascending=False)[:k].index for col, trs in zip(COLUMNS, TRANSITIONS)]\n",
    "    \n",
    "    ser = [(c, d) for c, d in zip(COLUMNS, WORDS)]\n",
    "    \n",
    "    md = \"\"\n",
    "    \n",
    "    for i, (col, s) in enumerate(ser):\n",
    "        if i > 0:\n",
    "            jac = round(jaccard(set(s), ser[i-1][-1]), 2)\n",
    "        else:\n",
    "            jac = None\n",
    "        \n",
    "        print(); md += \"\\n\"\n",
    "        print(col, \"jaccard =\", jac); md += f\"{col} jaccard = {jac}\"\n",
    "\n",
    "        if transition:\n",
    "            if as_table == False:\n",
    "                print(s)\n",
    "            else:\n",
    "                trans  = col.split(\"_\")[-1]\n",
    "                ti, tj = tuple(trans.split(\":\"))\n",
    "                table  = [] \n",
    "                for word in s:\n",
    "                    v    = df.loc[word][col]\n",
    "                    f_ti = int(df.loc[word][f\"frq_{ti}\"])\n",
    "                    f_tj = int(df.loc[word][f\"frq_{tj}\"])\n",
    "                    gch  = df.loc[word][f\"gch_{trans}\"]\n",
    "                    m    = df.loc[word][f\"mccc_{trans}\"]\n",
    "                    std  = df.loc[word][f\"stdc_{trans}\"]\n",
    "                    columns = [\"Word\", var.upper(), \"n_i\", \"n_j\", \"GCH\", \"Mctrl\", \"Sctrl\"]\n",
    "                    table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "                print(pd.DataFrame(table, columns=columns).dropna().round(3))\n",
    "                md += pd.DataFrame(table, columns=columns).dropna().round(3).to_markdown()\n",
    "        \n",
    "        else:\n",
    "            year = col.split(\"_\")[-1]\n",
    "            table = []\n",
    "            for word in s:\n",
    "                v    = df.loc[word][col]\n",
    "                f = int(df.loc[word][f\"frq_{year}\"])\n",
    "                columns = [\"Word\", var.upper(), \"Freq\"]\n",
    "                table.append([word, v, f])\n",
    "            print(pd.DataFrame(table, columns=columns).dropna().round(3))\n",
    "            md += pd.DataFrame(table, columns=columns).dropna().round(3).to_markdown()\n",
    "    if return_md:\n",
    "        return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_show(df, var, targets, th=4.781, return_md = False, min_freq=10):\n",
    "    \"\"\"\n",
    "    Given a dataframe, shows the value for a variable of target \n",
    "    each transition/year.\n",
    "    Provide threshold to only show the targets meeting the threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    md = \"\"\n",
    "\n",
    "    for col in sorted([col for col in df.columns if col.startswith(var)]):\n",
    "        trans  = col.split(\"_\")[-1]\n",
    "        ti, tj = tuple(trans.split(\":\"))\n",
    "        table  = [] \n",
    "        \n",
    "        for word in targets:\n",
    "            v    = df.loc[word][col]\n",
    "            f_ti = int(df.loc[word][f\"frq_{ti}\"])\n",
    "            f_tj = int(df.loc[word][f\"frq_{tj}\"])\n",
    "            if min_freq != None:\n",
    "                if f_ti < min_freq or f_tj < min_freq:\n",
    "                    continue\n",
    "            gch  = df.loc[word][f\"gch_{trans}\"]\n",
    "            m    = df.loc[word][f\"mccc_{trans}\"]\n",
    "            std  = df.loc[word][f\"stdc_{trans}\"]            \n",
    "            \n",
    "            if th != None:\n",
    "                if v > th:\n",
    "                    table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "            else:\n",
    "                table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "        \n",
    "        columns = [\"Word\", \"Value\", f\"n_{ti}\", f\"n_{tj}\", f\"gch_{ti}:{tj}\", f\"M_{ti}:{tj}\", f\"Std_{ti}:{tj}\"]\n",
    "        if table != []:\n",
    "            display = pd.DataFrame(table, columns=columns)\n",
    "            print(); md += \"\\n\" \n",
    "            print(col); md += f\"{col}\\n\"\n",
    "            print(display); md += display.to_markdown()\n",
    "    \n",
    "    if return_md:\n",
    "        return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_renamer(var_string):\n",
    "    var_string = var_string.split(\"_\")\n",
    "    yi, yj     = tuple(var_string[-1].split(\":\"))\n",
    "    yi         = yi[-2:]\n",
    "    yj         = yj[-2:]\n",
    "    return f\"{yi}:{yj}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(\n",
    "    df, \n",
    "    var, \n",
    "    targets, \n",
    "    prefixes = (\"N\", \"A\", \"V\"), \n",
    "    th=4.781, \n",
    "    transition = True, \n",
    "    min_freq = 10, \n",
    "    return_md = False,\n",
    "    rounder = 3\n",
    "):\n",
    "    \"\"\" \n",
    "    Similar to change_show but:\n",
    "    * Show data as one table\n",
    "    * Only show variable (change_show display additional data)\n",
    "    * Provide th to show True/False\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = sorted([col for col in df.columns if col.startswith(var)])\n",
    "    targets = [w for w in targets if w.startswith(prefixes)]\n",
    "    targets.sort()\n",
    "    if transition:\n",
    "        renamer = {k: v_renamer(k) for k in cols}\n",
    "    else:\n",
    "        renamer = {k: k.split(\"_\")[-1][-2:] for k in cols}\n",
    "    \n",
    "    md = \"\"\n",
    "    \n",
    "    if min_freq != None and transition:\n",
    "        df = df.copy()\n",
    "        transitions = find_transitions(df, \"df\", var)\n",
    "        for trg in targets:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var}_{ti}:{tj}\"] = 0\n",
    "\n",
    "    if min_freq != None and transition == False:\n",
    "        df = df.copy()\n",
    "        years = sorted([int(col.split(\"_\")[-1]) for col in cols])\n",
    "        for trg in targets:\n",
    "            for year in years:\n",
    "                if df.loc[trg][f\"frq_{year}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var}_{year}\"] = 0        \n",
    "                       \n",
    "    \n",
    "    if th != None:\n",
    "        out = df.loc[targets, cols] > th\n",
    "        out.rename(columns = renamer, inplace = True)\n",
    "        print(var.upper()); md += var.upper() + \"\\n\"\n",
    "        print(out); md += out.to_markdown()\n",
    "        print(\"SUM:\", out.sum().sum()); md += f\"\\nSUM: {out.sum().sum()}\\n\"\n",
    "    else:\n",
    "        out = df.loc[targets, cols].round(rounder)\n",
    "        out.rename(columns = renamer, inplace = True)\n",
    "        print(var.upper()); md += var.upper() + \"\\n\"\n",
    "        print(out); md += out.to_markdown()\n",
    "        print(\"SUM:\", out.sum().sum()); md += f\"\\nSUM: {out.sum().sum()}\\n\"\n",
    "    \n",
    "    if return_md:\n",
    "        return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path, sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dwts(df, path):\n",
    "    with open(Path(path), \"r\") as f:\n",
    "        dwt_roots = [w.strip(\"\\n\") for w in f.readlines()]\n",
    "    dwt_regex = re.compile(f\"({'|'.join(dwt_roots)})\")    \n",
    "    dwts = [str(w) for w in df.index if re.search(dwt_regex, str(w)) != None]\n",
    "    return dwts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(df):\n",
    "    \"\"\"\n",
    "    Summeraises variables of a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    yr_prefix = set()\n",
    "    tr_prefix = set()\n",
    "    years = set()\n",
    "    transitions = set()\n",
    "    \n",
    "    for v in df.columns:\n",
    "        prefix, suffix = tuple(v.split(\"_\"))\n",
    "        if \":\" in suffix:\n",
    "            tr_prefix.add(prefix)\n",
    "            transitions.add(suffix)\n",
    "        else:\n",
    "            yr_prefix.add(prefix)\n",
    "            years.add(suffix)\n",
    "    \n",
    "    return {\n",
    "        \"yr_prefix\": yr_prefix, \n",
    "        \"tr_prefix\": tr_prefix,\n",
    "        \"years\": years,\n",
    "        \"transitions\": transitions\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(word, transition, controls_dir, n_ctrl=10, variable=\"cosine_change\"):\n",
    "    \"\"\"\n",
    "    Goes to original data, shows the control change/similarity of a word \n",
    "    at a transition.\n",
    "    param word\n",
    "    param transition    tupple of ti and tj \n",
    "    param controls_dir  where to find controls\n",
    "    param variable      \"cosine_change\" or \"cosine_sim\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ti, tj = transition\n",
    "    basename = Path(controls_dir) / variable \n",
    "    \n",
    "    filenames = [f\"{ti}_{tj}_control{n}.txt\" for n in range(1, n_ctrl+1)]\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        data = load_metric(basename / file)\n",
    "        value = data[word] if word in data else \"NO MEASURE\"\n",
    "        values.append(value)\n",
    "        print(file, value)\n",
    "        \n",
    "    return values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncd(DATA, CORPUS, VAR, VAL): # No Change Detector\n",
    "\n",
    "    corpus = Path(CORPUS)\n",
    "    transitions = find_transitions(corpus / \"vocab\")    \n",
    "\n",
    "    for yi, yj in transitions:\n",
    "        print()\n",
    "        print(f\"{yi}:{yj}\")\n",
    "        \n",
    "        A = list(DATA[DATA[f\"{VAR}_{yi}:{yj}\"] == VAL].index)\n",
    "        print(\"No change (A):\", len(A))\n",
    "        B = list(DATA[DATA[f\"{VAR}_{yi}:{yj}\"] != VAL].index)\n",
    "        print(\"Other (B):\", len(B))\n",
    "        print()\n",
    "        print(\"{: <20} {}\".format(\"A\", \"B\"))\n",
    "        print(\"{: <20} {}\".format(\"---\", \"---\"))\n",
    "        for w1, w2 in zip(A[:100], B[:100]):\n",
    "            print(f\"{w1: <20} {w2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transitions(source, mode=\"file\", var = None):\n",
    "    \"\"\"\n",
    "    List transitions. \n",
    "    For mode = \"file\", expected source: filepath\n",
    "    For mode = \"df\", expected source: pandas DataFrame; provide varible var\n",
    "    \"\"\"\n",
    "    if mode == \"file\":\n",
    "        years = [int(file.strip(\".txt\")) for file in os.listdir(source)]\n",
    "        years.sort()\n",
    "        transitions = [(year, years[i]) for i, year in enumerate(years[:-1], start=1)]\n",
    "    if mode == \"df\":\n",
    "        cols = [col for col in source.columns if col.startswith(var)]\n",
    "        cols.sort()\n",
    "        transitions = [tuple(col.split(\"_\")[-1].split(\":\")) for col in cols]\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_overlap_checker(corpus, th_c):\n",
    "    \n",
    "    corpus = Path(corpus)\n",
    "    transitions = find_transitions(corpus / \"vocab\")\n",
    "    \n",
    "    for yi, yj in transitions:\n",
    "        print()\n",
    "        print(f\"{yi}:{yj}\")\n",
    "        \n",
    "        voc_a = load_metric(corpus / f\"vocab/{yi}.txt\")\n",
    "        voc_b = load_metric(corpus / f\"vocab/{yj}.txt\")\n",
    "\n",
    "        voc_a = {w: c for w, c in voc_a.items() if c >= th_c}\n",
    "        voc_b = {w: c for w, c in voc_b.items() if c >= th_c}\n",
    "        print(f\"{yi}:\", len(voc_a))\n",
    "        print(f\"{yj}:\", len(voc_b))\n",
    "        print(f\"{yi} and {yj}:\", len([w for w in voc_a.keys() if w in voc_b.keys()]))\n",
    "        print(f\"{yi} or {yj}:\", len(set(voc_a.keys()).union(set(voc_b.keys()))))\n",
    "        print(f\"{yi} - {yj}:\", len(set(voc_a.keys()).difference(set(voc_b.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df, var1, var2, mode=1, norm1=None, norm2=None, metric=\"pearson\"):    \n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    param norm1  function to normalize/transform var1 with (default None); provide function \n",
    "                 e.g. zscore or np.log \n",
    "    \"\"\"\n",
    "\n",
    "    transitions = find_transitions(df, \"df\", var1) \n",
    "    # Assumes `var1` and `var2` are both transition variables\n",
    "    # Consider implement `var1cut` parameter as in `universal_correlation`\n",
    "\n",
    "    if mode == 1:\n",
    "        correlation = df[[f\"{var1}_{ti}:{tj}\" for ti, tj in transitions]].corrwith(df[[f\"{var2}_{ti}:{tj}\" for ti, tj in transitions]], axis=1)\n",
    "    \n",
    "    if mode == 2:\n",
    "        table = []\n",
    "        for w in df.index:\n",
    "            valid = []\n",
    "            X = df[[f\"{var1}_{ti}:{tj}\" for ti, tj in transitions]].loc[w]\n",
    "            Y = df[[f\"{var2}_{ti}:{tj}\" for ti, tj in transitions]].loc[w]\n",
    "            for x, y in zip(X, Y):\n",
    "                if pd.isna(x):\n",
    "                    continue\n",
    "                if pd.isna(y):\n",
    "                    continue\n",
    "                valid.append((x, y))\n",
    "            \n",
    "            N = len(valid)\n",
    "            \n",
    "            if N < 2:\n",
    "                v = np.nan\n",
    "                p = np.nan\n",
    "            else:\n",
    "                X, Y = zip(*valid)\n",
    "                if norm1 != None:\n",
    "                    X = norm1(X)\n",
    "                if norm2 != None:\n",
    "                    Y = norm2(Y)\n",
    "                if metric == \"pearson\":\n",
    "                    R_data = pearsonr(X, Y)\n",
    "                    v = R_data.statistic\n",
    "                    p = R_data.pvalue\n",
    "\n",
    "                if metric == \"spearman\":\n",
    "                    R_data = spearmanr(X, Y)\n",
    "                    v = R_data.statistic\n",
    "                    p = R_data.pvalue\n",
    "                    \n",
    "            table.append([w, round(v, 2), round(p, 2), N])\n",
    "        correlation = pd.DataFrame(table, columns=[\"Word\", \"Correlation\", \"p\", \"N\"])\n",
    "        \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonaninf(x, y):\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    if pd.isna(y):\n",
    "        return False   \n",
    "    if abs(x) == np.inf:\n",
    "        return False\n",
    "    if abs(y) == np.inf:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonalist(lst):\n",
    "    for x in lst:\n",
    "        if pd.isna(x):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_var(df, var, varcut):\n",
    "    X = []\n",
    "    varcol = sorted([col for col in df.columns if col.startswith(var)])\n",
    "    if varcut != None:\n",
    "        del varcol[varcut]\n",
    "    for col in varcol:\n",
    "        X.extend(list(df[col]))\n",
    "    return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_correlation(\n",
    "    df, \n",
    "    var1, \n",
    "    var2, \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    min_freq = None\n",
    "):\n",
    "    # https://stackoverflow.com/questions/16031056/how-to-form-tuple-column-from-two-columns-in-pandas\n",
    "    \n",
    "    if min_freq != None:\n",
    "        df = df.copy()\n",
    "        \n",
    "        t1 = find_transitions(df, \"df\", var1)\n",
    "        t2 = find_transitions(df, \"df\", var2)\n",
    "\n",
    "        if var1cut != None:\n",
    "            transitions = [t for t in t2]\n",
    "\n",
    "        for trg in [w for w in df.index]:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var2}_{ti}:{tj}\"] = np.nan     \n",
    "    \n",
    "    X = collect_var(df, var1, var1cut)\n",
    "    Y = collect_var(df, var2, var2cut)\n",
    "            \n",
    "    print(\"Length:\")\n",
    "    print(\"X:\", len(X))\n",
    "    print(\"Y:\", len(Y))\n",
    "    \n",
    "    X, Y = zip(*[(x, y) for x, y in zip(X, Y) if nonaninf(x,y)])\n",
    "        \n",
    "    if norm1 != None:\n",
    "        X = norm1(X)\n",
    "    if norm2 != None:\n",
    "        Y = norm2(Y)\n",
    "    \n",
    "    if metric == \"pearson\":\n",
    "        R_data = pearsonr(X, Y)\n",
    "    if metric == \"spearman\":\n",
    "        R_data = spearmanr(X, Y)\n",
    "        \n",
    "    v = R_data.statistic\n",
    "    p = R_data.pvalue\n",
    "    \n",
    "    return v, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparison(\n",
    "    dfs,\n",
    "    mnames,\n",
    "    var, \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", # no other mode supported at the moment ...\n",
    "    word=None, # not supported at the moment ... \n",
    "    metric=\"pearson\",\n",
    "):\n",
    "    \n",
    "    cols = [col for col in dfs[0].columns if col.startswith(var)] # based on first df\n",
    "    trgs = [trg for trg in get_dwts(dfs[0], targets)]              # based on first df\n",
    "    print(\"Targets:\", \", \".join(trgs))\n",
    "    trgs = [trg for trg in trgs if trg.startswith(prefix)] if prefix != None else trgs\n",
    "    \n",
    "    _XY = []\n",
    "    if mode == \"universal\":    \n",
    "        for model, mname in zip(dfs, mnames):\n",
    "            this_model = []\n",
    "            for col in cols:\n",
    "                this_model.extend(model.loc[trgs, col])\n",
    "            print(\"Length\", mname, len(this_model))\n",
    "            _XY.append(this_model)\n",
    "    \n",
    "    _XY = list(zip(*[xyz for xyz in zip(*_XY) if nonalist(xyz)])) # note: xyz is a variable for a tuple\n",
    "    \n",
    "    print(\"Length (no NaN):\")\n",
    "    for vector in _XY:\n",
    "        print(len(vector))\n",
    "    \n",
    "    _XY = [norm(model) for model in _XY] if norm != None else _XY\n",
    "    \n",
    "    if metric == \"pearson\":\n",
    "        R_data = np.corrcoef(_XY)\n",
    "    if metric == \"spearman\":\n",
    "        _XY = [rankdata(model) for model in _XY]\n",
    "        R_data = np.corrcoef(_XY)\n",
    "        \n",
    "    out = pd.DataFrame(R_data, columns=mnames, index=mnames).round(3)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(df, var):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = Path(\"../../dw_results/fb_pol-yearly-radical3.csv\")\n",
    "#file_path = Path(\"fb_pol-yearly-radical3.csv\")\n",
    "results_dir = Path(\"../../dw_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fb_pol-yearly-radical3-restricted.csv\n",
      "fb_pol-yearly-bert-sentence-bert-swedish-cased.csv\n",
      "fb_pol-yearly-bert-sts_fbmodel_big_40epochs.csv\n",
      "fb_pol-yearly-bert-fb_nli.csv\n",
      "fb_pol-yearly-radical3-full.csv\n",
      "fb_pol-yearly-bert-sts_fbmodel.csv\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(results_dir)\n",
    "_ = [print(file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwt_path = \"../data/utils/dwts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crp_tib = Path(\"/srv/data/gusbohom/root/corpora/toypol/time_bin/radical3/\")\n",
    "corpus = Path(\"/home/max/Corpora/flashback-pol-time/yearly/fb-pt-radical3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly = read_csv(results_dir / \"fb_pol-yearly-radical3-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_dwt = read_csv(results_dir / \"fb_pol-yearly-radical3-restricted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_nli = read_csv(results_dir / \"fb_pol-yearly-bert-fb_nli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_sts = read_csv(results_dir / \"fb_pol-yearly-bert-sts_fbmodel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_big = read_csv(results_dir / \"fb_pol-yearly-bert-sts_fbmodel_big_40epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_kb  = read_csv(results_dir / \"fb_pol-yearly-bert-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toypol = read_csv(Path(\"../../toypol-time_bin.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_time_bin = read_csv(results_dir / \"fb_pol-time_bin-radical3-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_time_bin_dwt = read_csv(results_dir / \"fb_pol-time_bin-radical3-restricted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "W = set()\n",
    "corpus = Path(\"/home/max/Corpora/flashback-pol-time/yearly/contexts/files\")\n",
    "for file in os.listdir(corpus):\n",
    "    with open(corpus / file) as f:\n",
    "        for line in f:\n",
    "            dwts = line.split(\"\\t\")[0]\n",
    "            W.update(dwts.split(\"; \"))\n",
    "print(len(W))\n",
    "for w in sorted(list(W)):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_bert_sts[\"P1_självständig_utrikespolitik\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1_globalistisk\n",
      "N1_berikare\n",
      "N1_förortsgäng\n",
      "N1_globalist\n",
      "N1_kulturberikare\n",
      "N1_återvandring\n",
      "N2_återvandrare\n",
      "V1_berika\n",
      "V1_hjälpa_på_plats\n",
      "V1_kulturberika\n",
      "V1_återvandra\n"
     ]
    }
   ],
   "source": [
    "for w in sorted([w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1_globalistisk\n",
      "N1C_berikareX\n",
      "N1C_globalistX\n",
      "N1C_kulturberikarX\n",
      "N1C_återvandringsX\n",
      "N1_berikare\n",
      "N1_förortsgäng\n",
      "N1_globalist\n",
      "N1_kulturberikare\n",
      "N1_återvandring\n",
      "N2C_återvandrarX\n",
      "N2_återvandrare\n",
      "V1_berika\n",
      "V1_hjälpa_på_plats\n",
      "V1_kulturberika\n",
      "V1_återvandra\n"
     ]
    }
   ],
   "source": [
    "for w in sorted([w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11 * 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"gch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", # no other mode supported at the moment ...\n",
    "    word=None, # not supported at the moment ... \n",
    "    metric=\"pearson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_comparison(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"rch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", # no other mode supported at the moment ...\n",
    "    word=None, # not supported at the moment ... \n",
    "    metric=\"pearson\"\n",
    ").to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ncd(DATA=df_yearly, CORPUS=corpus, VAR=\"gsim\", VAL=1.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_overlap_checker(corpus=corpus, th_c=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_yearly, \"rch\", as_table = True)\n",
    "# q_show(\"rsim\")\n",
    "# q_show(\"gch\")\n",
    "# q_show(\"gsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker(\n",
    "    word=\"gyllene\", \n",
    "    transition=(2000,2001), \n",
    "    controls_dir=\"/home/max/Results/fb_pol-yearly-rad3\", \n",
    "    n_ctrl=10, \n",
    "    variable=\"cosine_change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_show(df_yearly, \"gch\", as_table = True, min_freq=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_nli, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_nli, \"gch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_nli, \"spr\", as_table = True, transition=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_show(df_bert_nli, \"anospr\", as_table = True, transition=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_sts, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_sts, \"gch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_bert_sts, \"spr\", as_table = True, transition=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_show(df_bert_sts, \"anospr\", as_table = True, transition=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS (big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#q_show(toypol, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#q_show(toypol, \"gsim\", as_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_time_bin, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def overview(\n",
    "    df, \n",
    "    var, \n",
    "    targets, \n",
    "    prefixes = (\"N\", \"A\", \"V\"), \n",
    "    th=4.781, \n",
    "    transition = True, \n",
    "    min_freq = 10, \n",
    "    return_md = False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGNS - only DWTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = overview(df_yearly_dwt, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_show(df, var, targets, th=4.781)\n",
    "change_show(df_yearly_dwt, \"rch\", get_dwts(df_yearly_dwt, dwt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_show(df_yearly_dwt, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_show(df_yearly_dwt, \"gsim\", get_dwts(df_yearly_dwt, dwt_path), th=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overview(df_bert_nli, \"anospr\", get_dwts(df_yearly_dwt, dwt_path), th=None, transition=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overview(df_bert_nli, \"difspr\", get_dwts(df_yearly_dwt, dwt_path), th=None, transition=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"frq\", get_dwts(df_yearly_dwt, dwt_path), th= None, transition = False, min_freq = None)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"gch\", get_dwts(df_yearly_dwt, dwt_path), th= None, transition = True, min_freq = None, return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), min_freq = 10, return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_show(df_bert_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bert_sts.loc[\"V1_berika\"][\"gsim_2008:2009\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"anospr\", get_dwts(df_yearly_dwt, dwt_path), th=None, transition = False, min_freq = None, return_md=True, rounder = 2)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"anospr\", get_dwts(df_yearly_dwt, dwt_path), th=-2, transition = False, min_freq = None, return_md=True, rounder = 2)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS (big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_kb, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_show(df_time_bin_dwt, \"rch\", get_dwts(df_time_bin_dwt, dwt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_show(df_time_bin_dwt, \"gsim\", get_dwts(df_time_bin_dwt, dwt_path), th=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=load_metric(\"/srv/data/gusbohom/root/corpora/fb_pol/time_bin/radical3/vocab/2015.txt\")[\"V1_berika\"]\n",
    "b=load_metric(\"/srv/data/gusbohom/root/corpora/fb_pol/time_bin/radical3/vocab/2019.txt\")[\"V1_berika\"]\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_variables(df_yearly_dwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All words (SGNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"frq\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gsim\", \n",
    "    var2=\"frq\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"frq\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"stdc\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DWTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>p</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1_berika</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.56</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1_kulturberikare</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1_berikare</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1_kulturberika</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N1_förortsgäng</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N1_globalist</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N1_återvandring</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1_globalistisk</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>antiglobalister</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V1_återvandra</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oberikat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V1_hjälpa_på_plats</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oberikade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oberikad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N2_återvandrare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>antiglobalist</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>antiglobalistisk</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P1_självständig_utrikespolitik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>biståndsåtervandring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>antiglobalistiska</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>antiglobalistiskt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vänsterglobalister</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>massåtervandring</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>återvandras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>massåtervandringen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vänsterglobalisterna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Word  Correlation     p   N\n",
       "0                        V1_berika        -0.13  0.56  22\n",
       "1                N1_kulturberikare        -0.39  0.10  19\n",
       "2                      N1_berikare        -0.43  0.10  16\n",
       "3                  V1_kulturberika        -0.53  0.04  16\n",
       "4                   N1_förortsgäng         0.02  0.98   6\n",
       "5                     N1_globalist        -0.19  0.47  17\n",
       "6                  N1_återvandring        -0.40  0.14  15\n",
       "7                  A1_globalistisk        -0.32  0.27  14\n",
       "8                  antiglobalister        -0.88  0.02   6\n",
       "9                    V1_återvandra        -0.56  0.03  15\n",
       "10                        oberikat          NaN   NaN   0\n",
       "11              V1_hjälpa_på_plats        -0.63  0.02  13\n",
       "12                       oberikade          NaN   NaN   1\n",
       "13                        oberikad          NaN   NaN   0\n",
       "14                 N2_återvandrare          NaN   NaN   1\n",
       "15                   antiglobalist        -0.89  0.11   4\n",
       "16                antiglobalistisk        -0.73  0.48   3\n",
       "17  P1_självständig_utrikespolitik          NaN   NaN   1\n",
       "18            biståndsåtervandring          NaN   NaN   0\n",
       "19               antiglobalistiska        -0.84  0.36   3\n",
       "20               antiglobalistiskt          NaN   NaN   0\n",
       "21              vänsterglobalister          NaN   NaN   0\n",
       "22                massåtervandring        -0.90  0.10   4\n",
       "23                     återvandras          NaN   NaN   0\n",
       "24              massåtervandringen          NaN   NaN   0\n",
       "25            vänsterglobalisterna          NaN   NaN   0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(df=df_yearly_dwt, \n",
    "            var1=\"diffpm\", \n",
    "            var2=\"rch\", \n",
    "            mode=2, \n",
    "            metric = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_yearly_dwt, var1=\"stdc\", var2=\"rch\", corpus=corpus, mode=2, metric = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_yearly_dwt, var1=\"diffpm\", var2=\"rch\", corpus=corpus, mode=2, metric = \"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def universal_correlation(\n",
    "    df, \n",
    "    var1, \n",
    "    var2, \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 3342680\n",
      "Y: 3342680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3944829273050009, 0.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_yearly, \"fpm\", \"gch\", -1, norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 3342680\n",
      "Y: 3342680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47518719624787575, 0.0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_yearly, \"fpm\", \"gch\", 0, norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 242\n",
      "Y: 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.38421898291972817, 8.683424766812245e-07)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 242\n",
      "Y: 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5454433760928777, 2.581384088189342e-13)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XXXXX MYSTERY --- WHAT IS WRONG????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"N1_kulturberikare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gch_2000:2001    0.153960\n",
       "gch_2001:2002    0.175314\n",
       "gch_2002:2003    0.241027\n",
       "gch_2003:2004    0.224313\n",
       "gch_2004:2005    0.116676\n",
       "gch_2005:2006    0.110975\n",
       "gch_2006:2007    0.085268\n",
       "gch_2007:2008    0.037758\n",
       "gch_2008:2009    0.027575\n",
       "gch_2009:2010    0.028536\n",
       "gch_2010:2011    0.026343\n",
       "gch_2011:2012    0.028605\n",
       "gch_2012:2013    0.034998\n",
       "gch_2013:2014    0.037272\n",
       "gch_2014:2015    0.042071\n",
       "gch_2015:2016    0.051824\n",
       "gch_2016:2017    0.057096\n",
       "gch_2017:2018    0.048862\n",
       "gch_2018:2019    0.044730\n",
       "gch_2019:2020    0.059805\n",
       "gch_2020:2021    0.055875\n",
       "Name: N1_kulturberikare, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert_sts.loc[term, [f\"gch_{year}:{year+1}\" for year in range(2000, 2021)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gch_2000:2001         NaN\n",
       "gch_2001:2002         NaN\n",
       "gch_2002:2003         NaN\n",
       "gch_2003:2004         NaN\n",
       "gch_2004:2005         NaN\n",
       "gch_2005:2006         NaN\n",
       "gch_2006:2007         NaN\n",
       "gch_2007:2008    0.219318\n",
       "gch_2008:2009    0.114512\n",
       "gch_2009:2010    0.184641\n",
       "gch_2010:2011    0.101501\n",
       "gch_2011:2012    0.156341\n",
       "gch_2012:2013    0.159321\n",
       "gch_2013:2014    0.151317\n",
       "gch_2014:2015    0.138897\n",
       "gch_2015:2016    0.151033\n",
       "gch_2016:2017    0.153216\n",
       "gch_2017:2018    0.190510\n",
       "gch_2018:2019    0.167800\n",
       "gch_2019:2020    0.170409\n",
       "gch_2020:2021    0.147955\n",
       "Name: N1_återvandring, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yearly.loc[term, [f\"gch_{year}:{year+1}\" for year in range(2000, 2021)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.3695514038282578, 1.0564019961786586e-07)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_nli.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10 \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.3742769767446603, 7.042170125875048e-08)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_nli.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STS (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5121676273693373, 1.9617372373764773e-14)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.49821858116838763, 1.2512269997698762e-13)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STS (big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.4878077195928632, 4.726511123934486e-13)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_big.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.47337258146226285, 2.7748853412631296e-12)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_big.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.4485492677844077, 4.8284906751498125e-11)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:\n",
      "X: 352\n",
      "Y: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.47337258146226285, 2.7748853412631296e-12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_correlation(df_bert_big.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
