{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from util import load_metric\n",
    "from scipy.stats import spearmanr, pearsonr, zscore, rankdata\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    return len(a.intersection(b)) / len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_renamer(var_string):\n",
    "    var_string = var_string.split(\"_\")\n",
    "    yi, yj     = tuple(var_string[-1].split(\":\"))\n",
    "    yi         = yi[-2:]\n",
    "    yj         = yj[-2:]\n",
    "    return f\"{yi}:{yj}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path, sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dwts(df, path):\n",
    "    with open(Path(path), \"r\") as f:\n",
    "        dwt_roots = [w.strip(\"\\n\") for w in f.readlines()]\n",
    "    dwt_regex = re.compile(f\"({'|'.join(dwt_roots)})\")    \n",
    "    dwts = [str(w) for w in df.index if re.search(dwt_regex, str(w)) != None]\n",
    "    return dwts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(df):\n",
    "    \"\"\"\n",
    "    Summeraises variables of a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    yr_prefix = set()\n",
    "    tr_prefix = set()\n",
    "    years = set()\n",
    "    transitions = set()\n",
    "    \n",
    "    for v in df.columns:\n",
    "        prefix, suffix = tuple(v.split(\"_\"))\n",
    "        if \":\" in suffix:\n",
    "            tr_prefix.add(prefix)\n",
    "            transitions.add(suffix)\n",
    "        else:\n",
    "            yr_prefix.add(prefix)\n",
    "            years.add(suffix)\n",
    "    \n",
    "    return {\n",
    "        \"yr_prefix\": yr_prefix, \n",
    "        \"tr_prefix\": tr_prefix,\n",
    "        \"years\": years,\n",
    "        \"transitions\": transitions\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transitions(source, mode=\"file\", var = None):\n",
    "    \"\"\"\n",
    "    List transitions. \n",
    "    For mode = \"file\", expected source: filepath\n",
    "    For mode = \"df\", expected source: pandas DataFrame; provide varible var\n",
    "    \"\"\"\n",
    "    if mode == \"file\":\n",
    "        years = [int(file.strip(\".txt\")) for file in os.listdir(source)]\n",
    "        years.sort()\n",
    "        transitions = [(year, years[i]) for i, year in enumerate(years[:-1], start=1)]\n",
    "    if mode == \"df\":\n",
    "        cols = [col for col in source.columns if col.startswith(var)]\n",
    "        cols.sort()\n",
    "        transitions = [tuple(col.split(\"_\")[-1].split(\":\")) for col in cols]\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonaninf(x, y):\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    if pd.isna(y):\n",
    "        return False   \n",
    "    if abs(x) == np.inf:\n",
    "        return False\n",
    "    if abs(y) == np.inf:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonalist(lst):\n",
    "    for x in lst:\n",
    "        if pd.isna(x):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_var(df, var, varcut, include_labels=False):\n",
    "    X = []\n",
    "    labels = []\n",
    "    varcol = sorted([col for col in df.columns if col.startswith(var)])\n",
    "    if varcut != None:\n",
    "        del varcol[varcut]\n",
    "    #print(varcol)\n",
    "    for col in varcol:\n",
    "        X.extend(list(df[col]))\n",
    "        labels.extend(df.index)\n",
    "    if include_labels:\n",
    "        return X, labels\n",
    "    else:\n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_overlap_checker(corpus, th_c):\n",
    "    \n",
    "    corpus = Path(corpus)\n",
    "    transitions = find_transitions(corpus / \"vocab\")\n",
    "    \n",
    "    for yi, yj in transitions:\n",
    "        print()\n",
    "        print(f\"{yi}:{yj}\")\n",
    "        \n",
    "        voc_a = load_metric(corpus / f\"vocab/{yi}.txt\")\n",
    "        voc_b = load_metric(corpus / f\"vocab/{yj}.txt\")\n",
    "\n",
    "        voc_a = {w: c for w, c in voc_a.items() if c >= th_c}\n",
    "        voc_b = {w: c for w, c in voc_b.items() if c >= th_c}\n",
    "        print(f\"{yi}:\", len(voc_a))\n",
    "        print(f\"{yj}:\", len(voc_b))\n",
    "        print(f\"{yi} and {yj}:\", len([w for w in voc_a.keys() if w in voc_b.keys()]))\n",
    "        print(f\"{yi} or {yj}:\", len(set(voc_a.keys()).union(set(voc_b.keys()))))\n",
    "        print(f\"{yi} - {yj}:\", len(set(voc_a.keys()).difference(set(voc_b.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(word, transition, controls_dir, n_ctrl=10, variable=\"cosine_change\"):\n",
    "    \"\"\"\n",
    "    Goes to original data, shows the control change/similarity of a word \n",
    "    at a transition.\n",
    "    param word\n",
    "    param transition    tupple of ti and tj \n",
    "    param controls_dir  where to find controls\n",
    "    param variable      \"cosine_change\" or \"cosine_sim\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ti, tj = transition\n",
    "    basename = Path(controls_dir) / variable \n",
    "    \n",
    "    filenames = [f\"{ti}_{tj}_control{n}.txt\" for n in range(1, n_ctrl+1)]\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        data = load_metric(basename / file)\n",
    "        value = data[word] if word in data else \"NO MEASURE\"\n",
    "        values.append(value)\n",
    "        print(file, value)\n",
    "        \n",
    "    return values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncd(DATA, CORPUS, VAR, VAL): # No Change Detector\n",
    "\n",
    "    corpus = Path(CORPUS)\n",
    "    transitions = find_transitions(corpus / \"vocab\")    \n",
    "\n",
    "    for yi, yj in transitions:\n",
    "        print()\n",
    "        print(f\"{yi}:{yj}\")\n",
    "        \n",
    "        A = list(DATA[DATA[f\"{VAR}_{yi}:{yj}\"] == VAL].index)\n",
    "        print(\"No change (A):\", len(A))\n",
    "        B = list(DATA[DATA[f\"{VAR}_{yi}:{yj}\"] != VAL].index)\n",
    "        print(\"Other (B):\", len(B))\n",
    "        print()\n",
    "        print(\"{: <20} {}\".format(\"A\", \"B\"))\n",
    "        print(\"{: <20} {}\".format(\"---\", \"---\"))\n",
    "        for w1, w2 in zip(A[:100], B[:100]):\n",
    "            print(f\"{w1: <20} {w2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_show(df, var, k = 40, as_table = False, transition=True, min_freq=None, return_md=False):\n",
    "    \"\"\"\n",
    "    Given a dataframe, shows the top k words for variable var each year.\n",
    "    Note: as_table only sypported for transition variables!\n",
    "    \"\"\"\n",
    "    \n",
    "    COLUMNS = [col for col in sorted(df.columns) if col.startswith(var)]\n",
    "\n",
    "    if min_freq == None:    \n",
    "        WORDS = [df[col].sort_values(ascending=False)[:k].index for col in COLUMNS]\n",
    "    else:\n",
    "        TRANSITIONS = [tuple(col.split(\"_\")[-1].split(\":\")) for col in COLUMNS]\n",
    "        WORDS = [df[(df[f\"frq_{trs[0]}\"] >= min_freq) & (df[f\"frq_{trs[1]}\"] >= min_freq)][col].sort_values(ascending=False)[:k].index for col, trs in zip(COLUMNS, TRANSITIONS)]\n",
    "    \n",
    "    ser = [(c, d) for c, d in zip(COLUMNS, WORDS)]\n",
    "    \n",
    "    md = \"\"\n",
    "    \n",
    "    for i, (col, s) in enumerate(ser):\n",
    "        if i > 0:\n",
    "            jac = round(jaccard(set(s), ser[i-1][-1]), 2)\n",
    "        else:\n",
    "            jac = None\n",
    "        \n",
    "        print(); md += \"\\n\"\n",
    "        print(col, \"jaccard =\", jac); md += f\"{col} jaccard = {jac}\"\n",
    "\n",
    "        if transition:\n",
    "            if as_table == False:\n",
    "                print(s)\n",
    "            else:\n",
    "                trans  = col.split(\"_\")[-1]\n",
    "                ti, tj = tuple(trans.split(\":\"))\n",
    "                table  = [] \n",
    "                for word in s:\n",
    "                    v    = df.loc[word][col]\n",
    "                    f_ti = int(df.loc[word][f\"frq_{ti}\"])\n",
    "                    f_tj = int(df.loc[word][f\"frq_{tj}\"])\n",
    "                    gch  = df.loc[word][f\"gch_{trans}\"]\n",
    "                    m    = df.loc[word][f\"mccc_{trans}\"]\n",
    "                    std  = df.loc[word][f\"stdc_{trans}\"]\n",
    "                    columns = [\"Word\", var.upper(), \"n_i\", \"n_j\", \"GCH\", \"Mctrl\", \"Sctrl\"]\n",
    "                    table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "                print(pd.DataFrame(table, columns=columns).dropna().round(3))\n",
    "                md += pd.DataFrame(table, columns=columns).dropna().round(3).to_markdown()\n",
    "        \n",
    "        else:\n",
    "            year = col.split(\"_\")[-1]\n",
    "            table = []\n",
    "            for word in s:\n",
    "                v    = df.loc[word][col]\n",
    "                f = int(df.loc[word][f\"frq_{year}\"])\n",
    "                columns = [\"Word\", var.upper(), \"Freq\"]\n",
    "                table.append([word, v, f])\n",
    "            print(pd.DataFrame(table, columns=columns).dropna().round(3))\n",
    "            md += pd.DataFrame(table, columns=columns).dropna().round(3).to_markdown()\n",
    "    if return_md:\n",
    "        return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_show(df, var, targets, th=4.781, return_md = False, min_freq=10):\n",
    "    \"\"\"\n",
    "    Given a dataframe, shows the value for a variable of target \n",
    "    each transition/year.\n",
    "    Provide threshold to only show the targets meeting the threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    md = \"\"\n",
    "\n",
    "    for col in sorted([col for col in df.columns if col.startswith(var)]):\n",
    "        trans  = col.split(\"_\")[-1]\n",
    "        ti, tj = tuple(trans.split(\":\"))\n",
    "        table  = [] \n",
    "        \n",
    "        for word in targets:\n",
    "            v    = df.loc[word][col]\n",
    "            f_ti = int(df.loc[word][f\"frq_{ti}\"])\n",
    "            f_tj = int(df.loc[word][f\"frq_{tj}\"])\n",
    "            if min_freq != None:\n",
    "                if f_ti < min_freq or f_tj < min_freq:\n",
    "                    continue\n",
    "            gch  = df.loc[word][f\"gch_{trans}\"]\n",
    "            m    = df.loc[word][f\"mccc_{trans}\"]\n",
    "            std  = df.loc[word][f\"stdc_{trans}\"]            \n",
    "            \n",
    "            if th != None:\n",
    "                if v > th:\n",
    "                    table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "            else:\n",
    "                table.append([word, v, f_ti, f_tj, gch, m, std])\n",
    "        \n",
    "        columns = [\"Word\", \"Value\", f\"n_{ti}\", f\"n_{tj}\", f\"gch_{ti}:{tj}\", f\"M_{ti}:{tj}\", f\"Std_{ti}:{tj}\"]\n",
    "        if table != []:\n",
    "            display = pd.DataFrame(table, columns=columns)\n",
    "            print(); md += \"\\n\" \n",
    "            print(col); md += f\"{col}\\n\"\n",
    "            print(display); md += display.to_markdown()\n",
    "    \n",
    "    if return_md:\n",
    "        return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(\n",
    "    df, \n",
    "    var, \n",
    "    targets,\n",
    "    verbose = False,\n",
    "    prefixes = (\"N\", \"A\", \"V\"), \n",
    "    th=4.781,\n",
    "    reverse_th=False,\n",
    "    transition = True, \n",
    "    min_freq = 10, \n",
    "    return_md = False,\n",
    "    rounder = 3,\n",
    "    return_complex=False\n",
    "):\n",
    "    \"\"\" \n",
    "    Similar to change_show but:\n",
    "    * Show data as one table\n",
    "    * Only show variable (change_show display additional data)\n",
    "    * Provide th to show True/False\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = sorted([col for col in df.columns if col.startswith(var)])\n",
    "    targets = [w for w in targets if w.startswith(prefixes)]\n",
    "    targets.sort()\n",
    "    if transition:\n",
    "        renamer = {k: v_renamer(k) for k in cols}\n",
    "    else:\n",
    "        renamer = {k: k.split(\"_\")[-1][-2:] for k in cols}\n",
    "    \n",
    "    \n",
    "    \n",
    "    if min_freq != None and transition:\n",
    "        df = df.copy()\n",
    "        transitions = find_transitions(df, \"df\", var)\n",
    "        for trg in targets:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    #df.at[trg, f\"{var}_{ti}:{tj}\"] = 0\n",
    "                    df.at[trg, f\"{var}_{ti}:{tj}\"] = np.nan\n",
    "\n",
    "    if min_freq != None and transition == False:\n",
    "        df = df.copy()\n",
    "        years = sorted([int(col.split(\"_\")[-1]) for col in cols])\n",
    "        for trg in targets:\n",
    "            for year in years:\n",
    "                if df.loc[trg][f\"frq_{year}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var}_{year}\"] = 0        \n",
    "    \n",
    "    out = df.loc[targets, cols]\n",
    "    out.rename(columns = renamer, inplace = True)\n",
    "    \n",
    "    if return_complex:\n",
    "        redef_out = []\n",
    "        #out = out.apply(three_values(th=th))\n",
    "#         print(out)\n",
    "#         print([[y[-1] for y in x.tolist] for x in out.iterrows()])\n",
    "    \n",
    "        for word, row in out.iterrows():\n",
    "            this_row = []\n",
    "            #print(row)\n",
    "            for cell in row:\n",
    "                #print(cell, type(cell))\n",
    "                if pd.isna(cell):\n",
    "                    cell = None\n",
    "                else:\n",
    "                    if reverse_th:\n",
    "                        if cell < th:\n",
    "                            cell = 1\n",
    "                        else:\n",
    "                            cell = 0                        \n",
    "                        \n",
    "                    else:    \n",
    "                        if cell > th:\n",
    "                            cell = 1\n",
    "                        else:\n",
    "                            cell = 0\n",
    "                \n",
    "                this_row.append(cell)\n",
    "            redef_out.append(this_row)\n",
    "        out = pd.DataFrame(redef_out, index=targets, columns = cols)\n",
    "        out.rename(columns = renamer, inplace = True)\n",
    "        \n",
    "    else:\n",
    "        if th != None:\n",
    "            #print(df.loc[targets, cols])\n",
    "            #out = df.loc[targets, cols] > th\n",
    "            if reverse_th:\n",
    "                out = out < th\n",
    "            else:\n",
    "                out = out > th\n",
    "\n",
    "        else:\n",
    "            #out = df.loc[targets, cols].round(rounder)\n",
    "            out = out.round(rounder)\n",
    "\n",
    "    if verbose:\n",
    "        print(var.upper())\n",
    "        print(out) \n",
    "        print(\"SUM:\", out.sum().sum())            \n",
    "            \n",
    "    if return_md:\n",
    "        md = \"\"\n",
    "        md += var.upper() + \"\\n\"\n",
    "        md += out.to_markdown()\n",
    "        md += f\"\\nSUM: {out.sum().sum()}\\n\"\n",
    "        return md\n",
    "    else: \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layered_view(\n",
    "    dfs, \n",
    "    names = [\"A1\", \"A2\", \"A3\"], \n",
    "    as_pandas=True, \n",
    "    numerical=False, \n",
    "    spc_labels=False, \n",
    "    ignore_NA = False,\n",
    "    ignore_pos = False\n",
    "):\n",
    "    \n",
    "    #Create empty table\n",
    "    n_rows, n_cols = dfs[0].shape\n",
    "    n_cols = n_cols + 1\n",
    "    table = [[[] for j in range(n_cols)] for i in range(n_rows)]\n",
    "    #print(table)\n",
    "\n",
    "    # Add first column = the words\n",
    "    terms = dfs[0].index\n",
    "    if ignore_pos:\n",
    "        terms = [\"_\".join(term.split(\"_\")[1:]) for term in terms]\n",
    "    for i, word in enumerate(terms):\n",
    "        table[i][0].append(word)\n",
    "        #print(table)\n",
    "\n",
    "    # Update cells\n",
    "    names = [\"A1\", \"A2\", \"A3\"]\n",
    "    for name, df in zip(names, dfs):\n",
    "        if ignore_pos:\n",
    "            assert [row[0][0] for row in table] == [\"_\".join(idx.split(\"_\")[1:]) for idx in df.index]\n",
    "        else:\n",
    "            assert [row[0][0] for row in table] == list(df.index)\n",
    "        for i, (word, row) in enumerate(df.iterrows()):\n",
    "            for j, cell in enumerate(row, start=1):\n",
    "                # None (when expected freq < 5), NaN (when freq < 10), 1 (sign.), 0 (non-sign.)\n",
    "                if cell == 1:\n",
    "                    table[i][j].append(name)\n",
    "                if cell == None:\n",
    "                    table[i][j].append(f\"X-{name}\")\n",
    "                    continue\n",
    "                if pd.isna(cell):\n",
    "                    table[i][j].append(f\"NA-{name}\")\n",
    "\n",
    "    table = [[\",\".join(cell) for cell in row] for row in table]\n",
    "    \n",
    "    #Some replacements:\n",
    "    table = [[cell.replace(\"NA-A1,NA-A2,X-A3\", \"NA\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"NA-A1,NA-A2,NA-A3\", \"NA\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"NA-A1,NA-A3\", \"NA\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\",NA-A3\", \"\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"NA-A3\", \"\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"NA-A1\", \"\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\",X-A3\", \"~\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"X-A3\", \"~\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"A1,A2\", \"AVG\") for cell in row] for row in table]\n",
    "    table = [[cell.replace(\"A2,A3\", \"BERT\") for cell in row] for row in table]\n",
    "    if ignore_NA:\n",
    "        table = [[cell.replace(\"NA\", \"\") for cell in row] for row in table]\n",
    "    \n",
    "    #Convet to numerical (no. of sign.)\n",
    "    if numerical:\n",
    "        table = [[0 if cell == \"NA\"   else cell for cell in row] for row in table]\n",
    "        table = [[1 if cell == \"\"     else cell for cell in row] for row in table]\n",
    "        table = [[1 if cell == \"~\"    else cell for cell in row] for row in table]\n",
    "        table = [[2 if cell == \"A2~\"  else cell for cell in row] for row in table]\n",
    "        table = [[2 if cell == \"A2\"   else cell for cell in row] for row in table]\n",
    "        table = [[3 if cell == \"AVG\"  else cell for cell in row] for row in table]\n",
    "        if spc_labels:\n",
    "            table = [[4 if cell == \"BERT\" else cell for cell in row] for row in table]\n",
    "        else:\n",
    "            table = [[3 if cell == \"BERT\" else cell for cell in row] for row in table]\n",
    "    \n",
    "    if as_pandas:\n",
    "        table = pd.DataFrame(\n",
    "            data = [row[1:] for row in table], \n",
    "            index = [row[0] for row in table], \n",
    "            columns=dfs[0].columns\n",
    "        )\n",
    "        renamer = {k: v_renamer(k) for k in dfs[0].columns}\n",
    "        table.rename(columns = renamer, inplace = True)\n",
    "    \n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heated_layer(dfs, distinguish_BERT_from_AVG = True, ignore_pos=False):\n",
    "    # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    \n",
    "    my_df_num = layered_view(dfs, numerical=True, spc_labels=distinguish_BERT_from_AVG, ignore_pos=ignore_pos).sort_index()\n",
    "    my_df_lbl = layered_view(dfs, ignore_NA=True, ignore_pos=ignore_pos).sort_index()\n",
    "    \n",
    "    y = 6\n",
    "    x = y*2\n",
    "\n",
    "    plt.figure(figsize=(x, y), dpi=300)\n",
    "\n",
    "    # Check:\n",
    "    # https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pcolor.html\n",
    "    # param of pcolor can be used to draw grid\n",
    "\n",
    "    #colors_list = ['#FF5733', '#FFC300']\n",
    "    if distinguish_BERT_from_AVG:\n",
    "        colors_list = [\"darkgrey\", \"white\", \"yellow\", \"yellowgreen\", \"orange\"]\n",
    "        cmap = colors.ListedColormap(colors_list)\n",
    "        plt.pcolor(my_df_num, cmap = cmap, edgecolors = \"k\")\n",
    "    else:\n",
    "        plt.pcolor(my_df_num, cmap = 'Greens')\n",
    "\n",
    "\n",
    "    plt.yticks(np.arange(0.5, len(my_df_num.index), 1), my_df_num.index)\n",
    "    plt.xticks(np.arange(0.5, len(my_df_num.columns), 1), my_df_num.columns, rotation=45)\n",
    "\n",
    "    n_rows, n_cols = my_df_num.shape\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            text = plt.text(j+0.5, i+0.5, my_df_lbl.iloc[i][j], ha=\"center\", va=\"center\", color=\"k\")\n",
    "\n",
    "    #for line in range(n_cols):\n",
    "    #    plt.axvline(line, color=\"black\", linestyle=\"dashed\", linewidth=0.5)\n",
    "\n",
    "    #for line in range(n_rows):\n",
    "    #    plt.axhline(line, color=\"black\", linestyle=\"dashed\", linewidth=0.5)\n",
    "\n",
    "    #plt.grid(which=\"major\", color=\"k\", linestyle='--', linewidth=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(df, var, norm=None, transition = True, metric=\"pearson\", prefixes = (\"N\", \"A\", \"V\")):\n",
    "    \n",
    "    if transition:\n",
    "        T = find_transitions(source=df, mode = \"df\", var=var)\n",
    "    else:\n",
    "        cols = [col for col in df.columns if col.startswith(var)]\n",
    "        cols.sort()\n",
    "        T = [int(col.split(\"_\")[-1]) for col in cols]\n",
    "\n",
    "    Y = [n for n in range(len(T))]\n",
    "    table = []\n",
    "    for w in df.index:\n",
    "        \n",
    "        if prefixes != None:\n",
    "            if not w.startswith(prefixes):\n",
    "                continue\n",
    "        \n",
    "        if transition:\n",
    "            X = df[[f\"{var}_{ti}:{tj}\" for ti, tj in T]].loc[w]\n",
    "        else:\n",
    "            X = df[[f\"{var}_{t}\" for t in T]].loc[w]\n",
    "        \n",
    "        \n",
    "        valid = [(x, y) for x, y in zip(X, Y) if not pd.isna(x)]\n",
    "\n",
    "        N = len(valid)\n",
    "\n",
    "        if N < 2:\n",
    "            v = np.nan\n",
    "            p = np.nan\n",
    "        else:\n",
    "            X, Y = zip(*valid)\n",
    "            if norm != None:\n",
    "                X = norm(X)\n",
    "\n",
    "            if metric == \"pearson\":\n",
    "                R_data = pearsonr(X, Y)\n",
    "\n",
    "            if metric == \"spearman\":\n",
    "                R_data = spearmanr(X, Y)\n",
    "                \n",
    "            v = R_data.statistic\n",
    "            p = R_data.pvalue\n",
    "\n",
    "        table.append([w, round(v, 3), round(p, 5), N])\n",
    "    correlation = pd.DataFrame(table, columns=[\"Word\", \"Trend\", \"p\", \"N\"])\n",
    "        \n",
    "    return correlation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(\n",
    "    df, \n",
    "    var1,\n",
    "    var2, \n",
    "    mode=1,\n",
    "    varcutter=False, # Cuts var1\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    min_freq = 11 ### OBS!\n",
    "):    \n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    param norm1  function to normalize/transform var1 with (default None); provide function \n",
    "                 e.g. zscore or np.log \n",
    "    \"\"\"\n",
    "\n",
    "    transitions1 = find_transitions(df, \"df\", var1)\n",
    "    transitions2 = find_transitions(df, \"df\", var2)\n",
    "    \n",
    "    if min_freq != None:\n",
    "        df = df.copy()\n",
    "        \n",
    "        for trg in [w for w in df.index]:\n",
    "            for ti, tj in transitions2:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] <= min_freq or df.loc[trg][f\"frq_{tj}\"] <= min_freq:\n",
    "                    df.at[trg, f\"{var2}_{ti}:{tj}\"] = np.nan\n",
    "\n",
    "    if mode == 1:\n",
    "        correlation = df[[f\"{var1}_{ti}:{tj}\" for ti, tj in transitions]].corrwith(df[[f\"{var2}_{ti}:{tj}\" for ti, tj in transitions]], axis=1)\n",
    "    \n",
    "    if mode == 2:\n",
    "        table = []\n",
    "        for w in df.index:\n",
    "            valid = []\n",
    "            if varcutter:\n",
    "                X = df[[f\"{var1}_{t[0]}\" for t in transitions1]].loc[w]\n",
    "                #print(X)\n",
    "                X = X[:-1] # <-- Obs!\n",
    "            else:\n",
    "                X = df[[f\"{var1}_{ti}:{tj}\" for ti, tj in transitions1]].loc[w]\n",
    "            \n",
    "            \n",
    "                \n",
    "            Y = df[[f\"{var2}_{ti}:{tj}\" for ti, tj in transitions2]].loc[w]\n",
    "            for x, y in zip(X, Y):\n",
    "                if pd.isna(x):\n",
    "                    continue\n",
    "                if pd.isna(y):\n",
    "                    continue\n",
    "                valid.append((x, y))\n",
    "            \n",
    "            N = len(valid)\n",
    "            \n",
    "            if N < 2:\n",
    "                v = np.nan\n",
    "                p = np.nan\n",
    "            else:\n",
    "                X, Y = zip(*valid)\n",
    "                \n",
    "                if prenorm1 != None:\n",
    "                    X = prenorm1(X)\n",
    "                if prenorm2 != None:\n",
    "                    Y = prenorm2(Y)                \n",
    "                \n",
    "                if norm1 != None:\n",
    "                    X = norm1(X)\n",
    "                if norm2 != None:\n",
    "                    Y = norm2(Y)\n",
    "                    \n",
    "                X, Y = zip(*[(x, y) for x, y in zip(X, Y) if nonaninf(x,y)])\n",
    "\n",
    "                if metric == \"pearson\":\n",
    "                    R_data = pearsonr(X, Y)\n",
    "                    v = R_data.statistic\n",
    "                    p = R_data.pvalue\n",
    "\n",
    "                if metric == \"spearman\":\n",
    "                    R_data = spearmanr(X, Y)\n",
    "                    v = R_data.statistic\n",
    "                    p = R_data.pvalue\n",
    "                    \n",
    "            table.append([w, round(v, 3), round(p, 3), N])\n",
    "        correlation = pd.DataFrame(table, columns=[\"Word\", \"Correlation\", \"p\", \"N\"])\n",
    "        \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlation(\n",
    "    df_bert_kb, \n",
    "    \"fpm\",\n",
    "    \"gch\", \n",
    "    mode=2,\n",
    "    varcutter=True, # Cuts var1\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    min_freq = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_correlation(\n",
    "    df, \n",
    "    var1, # X\n",
    "    var2, # Y\n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = None,\n",
    "    top_cut_off=None,\n",
    "    min_freq = None, # for large dataframes this is un-usable, as implemented below (iteration)\n",
    "    verbose=False\n",
    "):\n",
    "    # https://stackoverflow.com/questions/16031056/how-to-form-tuple-column-from-two-columns-in-pandas\n",
    "    \n",
    "    if top_n != None:\n",
    "        df = df.copy()\n",
    "        if top_cut_off != None:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[top_cut_off:top_n]\n",
    "        else:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[:top_n]\n",
    "        #print(df)\n",
    "    \n",
    "    if min_freq != None:\n",
    "        df = df.copy()\n",
    "        \n",
    "        t1 = find_transitions(df, \"df\", var1)\n",
    "        t2 = find_transitions(df, \"df\", var2)\n",
    "        \n",
    "        if var1cut != None:\n",
    "            transitions = [t for t in t2]\n",
    "            if verbose: \n",
    "                print(\"transitions\", transitions)\n",
    "        else:\n",
    "            transitions = [t for t in t1]\n",
    "        \n",
    "\n",
    "        for trg in [w for w in df.index]:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var2}_{ti}:{tj}\"] = np.nan\n",
    "    \n",
    "    X = collect_var(df, var1, var1cut)\n",
    "    Y = collect_var(df, var2, var2cut)\n",
    "    \n",
    "#     if verbose:\n",
    "#         print(\"Length:\")\n",
    "#         print(\"X:\", len(X))\n",
    "#         print(\"Y:\", len(Y))\n",
    "    \n",
    "    X, Y = zip(*[(x, y) for x, y in zip(X, Y) if nonaninf(x,y)])\n",
    "\n",
    "    if prenorm1 != None:\n",
    "        X = prenorm1(X)\n",
    "    if prenorm2 != None:\n",
    "        Y = prenorm2(Y) \n",
    "    \n",
    "    if norm1 != None:\n",
    "        X = norm1(X)\n",
    "    if norm2 != None:\n",
    "        Y = norm2(Y)\n",
    "    \n",
    "    X, Y = zip(*[(x, y) for x, y in zip(X, Y) if nonaninf(x,y)])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Length:\")\n",
    "        print(\"X:\", len(X))\n",
    "        print(\"Y:\", len(Y))    \n",
    "    \n",
    "    if metric == \"pearson\":\n",
    "        R_data = pearsonr(X, Y)\n",
    "    if metric == \"spearman\":\n",
    "        R_data = spearmanr(X, Y)\n",
    "    if metric == \"OLS\":\n",
    "        model = smf.ols(\"Y ~ X\", data=pd.DataFrame({\"X\": X, \"Y\": Y}))\n",
    "        #model = sm.OLS(Y, X)\n",
    "        #X = sm.add_constant(X) # https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html#statsmodels.regression.linear_model.OLS\n",
    "        results = model.fit()\n",
    "        print(results.summary())\n",
    "        \n",
    "        residuals = results.resid # residuals\n",
    "        fig = sm.qqplot(residuals)\n",
    "        plt.show()\n",
    "        return model\n",
    "    \n",
    "    v = R_data.statistic\n",
    "    p = R_data.pvalue\n",
    "    \n",
    "    return v, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_u_cor(\n",
    "    df, \n",
    "    var1, \n",
    "    var2, \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    top_n = None,\n",
    "    top_cut_off = None,\n",
    "    min_freq = None,\n",
    "    alpha=0.5,\n",
    "    ymax=None\n",
    "):\n",
    "    # https://stackoverflow.com/questions/16031056/how-to-form-tuple-column-from-two-columns-in-pandas\n",
    "    \n",
    "    if top_n != None:\n",
    "        df = df.copy()\n",
    "        if top_cut_off != None:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[top_cut_off:top_n]\n",
    "        else:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[:top_n]\n",
    "        #print(df)\n",
    "    \n",
    "    if min_freq != None:\n",
    "        df = df.copy()\n",
    "        \n",
    "        t1 = find_transitions(df, \"df\", var1)\n",
    "        t2 = find_transitions(df, \"df\", var2)\n",
    "        \n",
    "        if var1cut != None:\n",
    "            transitions = [t for t in t2]\n",
    "            print(\"transitions\", transitions)\n",
    "        else:\n",
    "            transitions = [t for t in t1]\n",
    "        \n",
    "\n",
    "        for trg in [w for w in df.index]:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var2}_{ti}:{tj}\"] = np.nan\n",
    "    \n",
    "    X = collect_var(df, var1, var1cut)\n",
    "    Y = collect_var(df, var2, var2cut)\n",
    "            \n",
    "#     print(\"Length:\")\n",
    "#     print(\"X:\", len(X))\n",
    "#     print(\"Y:\", len(Y))\n",
    "    \n",
    "    X, Y = zip(*[(x, y) for x, y in zip(X, Y) if nonaninf(x,y)])\n",
    "    \n",
    "    print(\"Length:\")\n",
    "    print(\"X:\", len(X))\n",
    "    print(\"Y:\", len(Y))    \n",
    "        \n",
    "    if norm1 != None:\n",
    "        X = norm1(X)\n",
    "    if norm2 != None:\n",
    "        Y = norm2(Y)\n",
    "    \n",
    "    if ymax != None:\n",
    "        plt.ylim(ymax = ymax, ymin=-ymax)\n",
    "    plt.scatter(X, Y, alpha=alpha)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_u_cor_with_labels(\n",
    "    df, \n",
    "    var1, \n",
    "    var2, \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    top_n = None,\n",
    "    top_cut_off = None,\n",
    "    min_freq = None,\n",
    "    alpha=0.5, \n",
    "    group=None\n",
    "):\n",
    "    # https://stackoverflow.com/questions/16031056/how-to-form-tuple-column-from-two-columns-in-pandas\n",
    "    \n",
    "    if top_n != None:\n",
    "        df = df.copy()\n",
    "        if top_cut_off != None:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[top_cut_off:top_n]\n",
    "        else:\n",
    "            df = df.sort_values(by=['tot_frq'], ascending=False)[:top_n]\n",
    "        #print(df)\n",
    "    \n",
    "    if min_freq != None:\n",
    "        df = df.copy()\n",
    "        \n",
    "        t1 = find_transitions(df, \"df\", var1)\n",
    "        t2 = find_transitions(df, \"df\", var2)\n",
    "        \n",
    "        if var1cut != None:\n",
    "            transitions = [t for t in t2]\n",
    "            print(\"transitions\", transitions)\n",
    "        else:\n",
    "            transitions = [t for t in t1]\n",
    "        \n",
    "\n",
    "        for trg in [w for w in df.index]:\n",
    "            for ti, tj in transitions:\n",
    "                if df.loc[trg][f\"frq_{ti}\"] < min_freq or df.loc[trg][f\"frq_{tj}\"] < min_freq:\n",
    "                    df.at[trg, f\"{var2}_{ti}:{tj}\"] = np.nan\n",
    "    \n",
    "    X, labels = collect_var(df, var1, var1cut, include_labels=True)\n",
    "    Y, _labels = collect_var(df, var2, var2cut, include_labels=True)\n",
    "    \n",
    "    assert labels == _labels\n",
    "            \n",
    "#     print(\"Length:\")\n",
    "#     print(\"X:\", len(X))\n",
    "#     print(\"Y:\", len(Y))\n",
    "    \n",
    "    X, Y, labels = zip(*[(x, y, label) for x, y, label in zip(X, Y, labels) if nonaninf(x,y)])\n",
    "    \n",
    "    if group != None:\n",
    "        for g in group:\n",
    "            g_name = \", \".join(g)\n",
    "            labels = [g_name if label in g else label for label in labels]\n",
    "        \n",
    "        labels = [\"Other\" if \",\" not in label else label for label in labels]\n",
    "                    \n",
    "    \n",
    "    label2key = {label: idx for idx, label in enumerate(set(labels))}\n",
    "    key2label = {idx: label for label, idx in label2key.items()}\n",
    "    \n",
    "    labels = [label2key[label] for label in labels]\n",
    "    \n",
    "    print(\"Length:\")\n",
    "    print(\"X:\", len(X))\n",
    "    print(\"Y:\", len(Y))    \n",
    "        \n",
    "    if norm1 != None:\n",
    "        X = norm1(X)\n",
    "    if norm2 != None:\n",
    "        Y = norm2(Y)\n",
    "    \n",
    "    # Redefine labels??!\n",
    "    # \n",
    "    \n",
    "    #scat=plt.scatter(X, Y, c=labels, alpha=alpha)\n",
    "    #plt.legend(*scat.legend_elements(), loc=\"lower left\", title=\"Classes\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 10), dpi=300)\n",
    "    \n",
    "    for color in key2label.keys():\n",
    "        x_L, y_L = zip(*[(x, y) for x, y, label in zip(X, Y, labels) if label == color])\n",
    "        plt.scatter(x_L, y_L, label= key2label[color], alpha=alpha)\n",
    "    \n",
    "    plt.legend(title=\"DWEs\")    \n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_cor(\n",
    "    df, \n",
    "    var1, \n",
    "    var2, \n",
    "    var1tr = True, \n",
    "    var2tr = True, \n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=None, \n",
    "    norm2=None\n",
    "):    \n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    param norm1  function to normalize/transform var1 with (default None); provide function \n",
    "                 e.g. zscore or np.log \n",
    "    \"\"\"\n",
    "\n",
    "    tr1 = find_transitions(df, \"df\", var1)\n",
    "    if var1tr == False:\n",
    "        tr1 = [f\"{var1}_{tr[0]}\" for tr in tr1] # Note choses 1st ## VAR CUT!\n",
    "    else:\n",
    "        tr1 = [f\"{var1}_{ti}:{tj}\" for ti, tj in tr1]\n",
    "    \n",
    "    tr2 = find_transitions(df, \"df\", var2)\n",
    "    if var2tr == False:\n",
    "        tr2 = [f\"{var2}_{tr[0]}\" for tr in tr2]\n",
    "    else:\n",
    "        tr2 = [f\"{var2}_{ti}:{tj}\" for ti, tj in tr2]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10), dpi=300)\n",
    "    nrows = int(len(df.index) / 2)\n",
    "    #fig, axs = plt.subplots(nrows, 2)\n",
    "    \n",
    "    \n",
    "    for iorder, w in enumerate(df.index[:-1], start=1):\n",
    "        print(w)\n",
    "        valid = []\n",
    "        transitions = []\n",
    "        X = df[tr1].loc[w]\n",
    "        Y = df[tr2].loc[w]\n",
    "        for x, y, transition in zip(X, Y, tr1):\n",
    "            if pd.isna(x):\n",
    "                continue\n",
    "            if pd.isna(y):\n",
    "                continue\n",
    "            valid.append((x, y))\n",
    "            transitions.append(transition)\n",
    "\n",
    "        N = len(valid)\n",
    "#         print(valid)\n",
    "#         print(transitions)\n",
    "\n",
    "        if N < 2:\n",
    "            continue\n",
    "            #print(\"Nope ...\")\n",
    "            #print()\n",
    "        else:\n",
    "            X, Y = zip(*valid)\n",
    "            \n",
    "            if prenorm1 != None:\n",
    "                X = prenorm1(X)\n",
    "            if prenorm2 != None:\n",
    "                Y = prenorm2(Y)\n",
    "                \n",
    "            if norm1 != None:\n",
    "                X = norm1(X)\n",
    "            if norm2 != None:\n",
    "                Y = norm2(Y)\n",
    "\n",
    "            #Tx = range(len(X))\n",
    "            #Ty = range(len(Y))\n",
    "            T = [int(trans[-4:]) for trans in transitions]\n",
    "\n",
    "            #plt.plot(Tx, X, Ty, Y, marker = 'o')\n",
    "            plt.subplot(nrows,2,iorder)\n",
    "            #plt.figure(figsize=(8, 8), dpi=300)\n",
    "            plt.plot(T, X, \"-b\", label=var1)\n",
    "            plt.plot(T, Y, \"-r\", label=var2)\n",
    "            plt.xticks(rotation=45, ha='right', fontsize='small')\n",
    "            plt.title(w, fontsize='medium')\n",
    "            \n",
    "            #handles, labels = ax.get_legend_handles_labels()\n",
    "            \n",
    "    plt.figlegend(labels=[var1, var2], loc='upper center', ncol=2)\n",
    "    leg = plt.legend()\n",
    "    #leg.get_frame().set_edgecolor('b') \n",
    "    #eg.get_frame().set_linewidth(2.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(df, term, variable, prefix = None, transition = True, norm=None):\n",
    "    \n",
    "    transitions = find_transitions(df, \"df\", variable)\n",
    "    if transition == False:\n",
    "        transitions = [x[0] for x in transitions]\n",
    "    \n",
    "    cols  = [f\"{variable}_{x}\" for x in transitions]\n",
    "    years = [int(x.split(\"_\")[-1]) for x in cols]\n",
    "    \n",
    "    if term == \"--ALL\":\n",
    "        terms = [w for w in df.index if w.startswith(prefix)] if prefix != None else df.index\n",
    "        for t in terms:\n",
    "            print(t.upper())\n",
    "            Y = []\n",
    "            for col in cols:\n",
    "                Y.append(df.loc[t, col])     \n",
    "    \n",
    "            plt.plot(years, Y)\n",
    "            plt.show()\n",
    "            if transition:\n",
    "                print(\"NOTE: Each X is a transition from previous!\")\n",
    "    else:\n",
    "        print(t.upper())\n",
    "        Y = []\n",
    "        for col in cols:\n",
    "            Y.append(df.loc[term, col])     \n",
    "\n",
    "        plt.plot(years, Y)\n",
    "        plt.show()\n",
    "        if transition:\n",
    "            print(\"NOTE: Each X is a transition from previous!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparison(\n",
    "    dfs,\n",
    "    mnames,\n",
    "    var,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=None, # A list of the same length as dfs and mnames\n",
    "    col_start=None, # To calibrate series of differnt length\n",
    "    metric=\"pearson\",\n",
    "):\n",
    "    \n",
    "    # Getting shared targets\n",
    "    pre_targets = [set([trg for trg in get_dwts(df, targets)]) for df in dfs]\n",
    "    trgs = set.intersection(*pre_targets)\n",
    "    \n",
    "    #trgs = [trg for trg in get_dwts(dfs[0], targets)]             # based on first df\n",
    "    trgs = [trg for trg in trgs if trg.startswith(prefix)] if prefix != None else trgs\n",
    "    print(\"Targets (shared):\")\n",
    "    print(\"\\n\".join(sorted(trgs)))    \n",
    "    \n",
    "    _XY = []\n",
    "    if mode == \"universal\":\n",
    "        \n",
    "        cols = [col for col in dfs[0].columns if col.startswith(var)] # based on first df\n",
    "        if col_start != None:\n",
    "            cols = [col for col in cols if int(col.split(\"_\")[-1].split[\":\"][0]) >= col_start]\n",
    "        \n",
    "        for model, mname in zip(dfs, mnames):\n",
    "            this_model = []\n",
    "            for col in cols:\n",
    "                this_model.extend(model.loc[trgs, col])\n",
    "            print(\"Length\", mname, len(this_model))\n",
    "            _XY.append(this_model)\n",
    "    \n",
    "    if mode == \"var_off\":\n",
    "        for model, mname, voff in zip(dfs, mnames, var_off):\n",
    "            \n",
    "            cols = [col for col in model.columns if col.startswith(voff)]\n",
    "            \n",
    "            #sort\n",
    "            interim = []\n",
    "            for col in cols:\n",
    "                variabel, this_transition = col.split(\"_\")\n",
    "                year_from, year_to = this_transition.split(\":\")\n",
    "                interim.append((variabel, year_from, year_to))\n",
    "            \n",
    "            interim = sorted(interim, key = lambda x: x[1]) # year_from\n",
    "            #print(interim)\n",
    "            cols = [f\"{x[0]}_{x[1]}:{x[2]}\" for x in interim]\n",
    "            \n",
    "            #print(cols)\n",
    "            if col_start != None:\n",
    "                cols = [col for col in cols if int(col.split(\"_\")[-1].split(\":\")[0]) >= col_start]\n",
    "            \n",
    "            this_model = []\n",
    "            for col in cols:\n",
    "                this_model.extend(model.loc[trgs, col])\n",
    "            #print(\"Length\", mname, len(this_model))\n",
    "            _XY.append(this_model)        \n",
    "    \n",
    "    Ns = [str(len(xy)) for xy in _XY]\n",
    "    print(\"Matrix-Size:\", \" \".join(Ns))\n",
    "    \n",
    "    _XY = list(zip(*[xyz for xyz in zip(*_XY) if nonalist(xyz)])) # note: xyz is a variable for a tuple\n",
    "    \n",
    "    Ns = [str(len(xy)) for xy in _XY]\n",
    "    print(\"Length (no NaN):\", \" \".join(Ns))\n",
    "    \n",
    "    _XY = [norm(model) for model in _XY] if norm != None else _XY\n",
    "    \n",
    "    if metric == \"pearson\":\n",
    "        R_data = np.corrcoef(_XY)\n",
    "    if metric == \"spearman\": # Perhaps recommended for mode = \"var_off\"?\n",
    "        _XY = [rankdata(model) for model in _XY]\n",
    "        R_data = np.corrcoef(_XY)\n",
    "        \n",
    "    out = pd.DataFrame(R_data, columns=mnames, index=mnames).round(3)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(\n",
    "    dfs,\n",
    "    mnames,\n",
    "    var,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=None, # A list of the same length as dfs and mnames\n",
    "    col_start=None, # To calibrate series of differnt length\n",
    "    metric=\"pearson\",\n",
    "):\n",
    "    \n",
    "    # Getting shared targets\n",
    "    pre_targets = [set([trg for trg in get_dwts(df, targets)]) for df in dfs]\n",
    "    trgs = set.intersection(*pre_targets)\n",
    "    \n",
    "    #trgs = [trg for trg in get_dwts(dfs[0], targets)]             # based on first df\n",
    "    trgs = [trg for trg in trgs if trg.startswith(prefix)] if prefix != None else trgs\n",
    "    print(\"Targets (shared):\")\n",
    "    print(\"\\n\".join(sorted(trgs)))    \n",
    "    \n",
    "    _XY = []\n",
    "    if mode == \"universal\":\n",
    "        \n",
    "        cols = [col for col in dfs[0].columns if col.startswith(var)] # based on first df\n",
    "        if col_start != None:\n",
    "            cols = [col for col in cols if int(col.split(\"_\")[-1].split[\":\"][0]) >= col_start]\n",
    "        \n",
    "        for model, mname in zip(dfs, mnames):\n",
    "            this_model = []\n",
    "            for col in cols:\n",
    "                this_model.extend(model.loc[trgs, col])\n",
    "            #print(\"Length\", mname, len(this_model))\n",
    "            _XY.append(this_model)\n",
    "    \n",
    "    if mode == \"var_off\":\n",
    "        for model, mname, voff in zip(dfs, mnames, var_off):\n",
    "            \n",
    "            cols = [col for col in model.columns if col.startswith(voff)]\n",
    "            #print(cols)\n",
    "            if col_start != None:\n",
    "                cols = [col for col in cols if int(col.split(\"_\")[-1].split(\":\")[0]) >= col_start]\n",
    "            \n",
    "            this_model = []\n",
    "            for col in cols:\n",
    "                this_model.extend(model.loc[trgs, col])\n",
    "            #print(\"Length\", mname, len(this_model))\n",
    "            _XY.append(this_model)        \n",
    "    \n",
    "    Ns = [str(len(xy)) for xy in _XY]\n",
    "    print(\"Matrix-Size:\", \" \".join(Ns))\n",
    "    \n",
    "    _XY = list(zip(*[xyz for xyz in zip(*_XY) if nonalist(xyz)])) # note: xyz is a variable for a tuple\n",
    "    \n",
    "    out = [series for series in zip(mnames, _XY)]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = Path(\"../../dw_results/fb_pol-yearly-radical3.csv\")\n",
    "#file_path = Path(\"fb_pol-yearly-radical3.csv\")\n",
    "results_dir = Path(\"../../dw_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-v0\n",
      "change_tables\n",
      "fb_pol-time_bin-radical3-full.csv\n",
      "fb_pol-time_bin-radical3-restricted.csv\n",
      "fb_pol-yearly-bert-fb_nli.csv\n",
      "fb_pol-yearly-bert-sentence-bert-swedish-cased.csv\n",
      "fb_pol-yearly-bert-sts_fbmodel.csv\n",
      "fb_pol-yearly-bert-sts_fbmodel_big_40epochs.csv\n",
      "fb_pol-yearly-cluster-sentence-bert-swedish-cased.csv\n",
      "fb_pol-yearly-radical3-full.csv\n",
      "fb_pol-yearly-radical3-restricted.csv\n",
      "fm_smh-yearly-bert-sentence-bert-swedish-cased.csv\n",
      "fm_smh-yearly-cluster-sentence-bert-swedish-cased.csv\n",
      "fm_smh-yearly-radical3-full.csv\n",
      "fm_smh-yearly-radical3-restricted.csv\n",
      "messy-05-09-2023\n",
      "neighbors\n"
     ]
    }
   ],
   "source": [
    "files = sorted(os.listdir(results_dir))\n",
    "_ = [print(file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwt_path = \"../data/utils/dwts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crp_tib = Path(\"/srv/data/gusbohom/root/corpora/toypol/time_bin/radical3/\")\n",
    "corpus = Path(\"/home/max/Corpora/flashback-pol-time/yearly/fb-pt-radical3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly = read_csv(results_dir / \"fb_pol-yearly-radical3-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_dwt = read_csv(results_dir / \"fb_pol-yearly-radical3-restricted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_nli = read_csv(results_dir / \"fb_pol-yearly-bert-fb_nli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_sts = read_csv(results_dir / \"fb_pol-yearly-bert-sts_fbmodel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_big = read_csv(results_dir / \"fb_pol-yearly-bert-sts_fbmodel_big_40epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_kb  = read_csv(results_dir / \"fb_pol-yearly-bert-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_ref = read_csv(results_dir / \"fm_smh-yearly-radical3-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_ref_dwt = read_csv(results_dir / \"fm_smh-yearly-radical3-restricted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_kb_ref = read_csv(results_dir / \"fm_smh-yearly-bert-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn = read_csv(results_dir / \"fb_pol-time_bin-radical3-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn_dwt = read_csv(results_dir / \"fb_pol-time_bin-radical3-restricted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn_nli = read_csv(results_dir / \"fb_pol-time_bin-bert-fb_nli.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn_sts = read_csv(results_dir / \"fb_pol-time_bin-bert-sts_fbmodel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn_big = read_csv(results_dir / \"fb_pol-time_bin-bert-sts_fbmodel_big_40epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tbn_kb = read_csv(results_dir / \"fb_pol-time_bin-bert-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = read_csv(results_dir / \"fb_pol-yearly-cluster-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_ref = read_csv(results_dir / \"fm_smh-yearly-cluster-sentence-bert-swedish-cased.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DWTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DWTs = get_dwts(df_yearly_dwt, dwt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most terms increases over time. But see separate figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trend(df_yearly_dwt, var=\"frq\", norm=None, transition = False, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(df_bert_sts, var=\"frq\", norm=None, transition = False, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Note-to-self:** what's going on here?!) Considering SGNS models, only for \"N1_berikare\" there is a negative trend of less semantic change over time (both GCH and RCH). For other terms, this is not so. Considering STS, there is a negative trend for GCH for several terms, but only for \"N1_berikare\" and \"N1_frortsgng\" for RCH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend(df_yearly_dwt, var=\"gch\", norm=None, transition = True, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend(df_yearly_dwt, var=\"rch\", norm=None, transition = True, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend(df_bert_sts, var=\"gch\", norm=None, transition = True, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend(df_bert_sts, var=\"rch\", norm=None, transition = True, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Approach 1, 2, 3\n",
    "* *GCH* and *RCH* \n",
    "* Note param `var_off`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note-to-self:** New grouping of compounds with simples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in sorted([w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in sorted([w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in sorted([w for w in df_yearly_ref_dwt.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in sorted([w for w in df_bert_kb_ref.index if w.startswith((\"N\", \"A\", \"V\"))]):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Considering GCH and yearly transitions, SGNS is negatively correlated with BERT models\n",
    "* With RCH, there is positive correlation.\n",
    "* With RCH, the BERT models are less strongly correlated. \n",
    "* Considering four year time bins, there is only positive correlation (both GCH and RCH). The correlation for SGNS and BERT is stronger for RCH than for GCH. \n",
    "* As with yearly transitions, BERT models are less correlated with RCH than GCH. However, there are very strong correlations of RCH for BERT models given four year time bins experiments. The \"lessen effect by RCH\" is smaller in time bins experiments than yearly experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the number 242 comes from..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "11 * 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Genuine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the series (variables) normally distributed? (No.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = get_series(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"gch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, s in series:\n",
    "    print(name)\n",
    "    plt.hist(s, bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, **no Pearson**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"gch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", \n",
    "#     metric=\"pearson\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_comparison(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"gch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", \n",
    "    metric=\"spearman\"\n",
    ").to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series = get_series(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"rch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, s in series:\n",
    "    print(name)\n",
    "    plt.hist(s, bins=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, no Pearson!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"rch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", # no other mode supported at the moment ...\n",
    "#     metric=\"pearson\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... with rank-based correlation, i.e. Spearman's, there is higher correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_comparison(\n",
    "    dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "    mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "    var=\"rch\", \n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"universal\", # no other mode supported at the moment ...\n",
    "    metric=\"spearman\"\n",
    ").to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four year time bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_tbn_dwt, df_tbn_nli, df_tbn_sts, df_tbn_big, df_tbn_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"gch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", # no other mode supported at the moment ...\n",
    "#     metric=\"pearson\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_tbn_dwt, df_tbn_nli, df_tbn_sts, df_tbn_big, df_tbn_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"rch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", # no other mode supported at the moment ...\n",
    "#     metric=\"pearson\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... with rank-based correlation, i.e. Spearman's, there is (mostly) higher correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_tbn_dwt, df_tbn_nli, df_tbn_sts, df_tbn_big, df_tbn_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"rch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", # no other mode supported at the moment ...\n",
    "#     metric=\"spearman\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The cluster approches are strongly correlated with each other; especially the K-Means approaches.\n",
    "* If any, the Agglomerative clustering with cosine similiarity (ACS) is the \"odd one out\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note-to-self:** Due to memory issues ACS methods are (at the momen) removed from terms with too much data. Can this be solved by something corresponding to KMeans-batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = get_series(\n",
    "    dfs = [df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"kms\", \"km5\", \"kmsr50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"kms_\", \"km5\", \"kmsr50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, s in series:\n",
    "    print(name)\n",
    "    plt.hist(s, bins=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_comparison(\n",
    "#     dfs = [df_cluster, df_cluster, df_cluster],\n",
    "#     mnames = [\"kms\", \"km5\", \"kmsr50\"],\n",
    "#     var = None,\n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"var_off\", \n",
    "#     # Mode:\n",
    "#     # \"universal\"  Uses the same variable for comparison\n",
    "#     # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "#     var_off=[\"kms\", \"km5\", \"kmsr50\"], # A list of the same length as dfs and mnames\n",
    "#     metric=\"pearson\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_comparison(\n",
    "#     dfs = [df_cluster, df_cluster, df_cluster, df_cluster, df_cluster],\n",
    "#     mnames = [\"kms\", \"km5\", \"kmsr50\", \"acs\", \"acsr50\"],\n",
    "#     var = None,\n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"var_off\", \n",
    "#     # Mode:\n",
    "#     # \"universal\"  Uses the same variable for comparison\n",
    "#     # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "#     var_off=[\"kms\", \"km5\", \"kmsr50\", \"acs\", \"acsr50\"], # A list of the same length as dfs and mnames\n",
    "#     metric=\"pearson\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With spearman ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_cluster, df_cluster, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"kms\", \"km5\", \"kmsr50\", \"acs\", \"acsr50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"kms_\", \"km5\", \"kmsr50\", \"acs\", \"acsr50\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1, 2, and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The cluster approaches are *not* correlated with SGNS - not for GCH, nor RCH. \n",
    "* The cluster approaches *are* correlated with the averaging BERT approaches, *when considering GCH* (not RCH).\n",
    "* There is no correlation for clusterapproaches and BERT when considering RCH. \n",
    "* Thus, for RCH, the cluster approaches are *not* correlated with any of the averaging approaches (word2vec and BERT with one-centroid). \n",
    "\n",
    "**Is there any way to rectify the cluster-based measures?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genuine change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = get_series(\n",
    "#     dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "#     mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "#     var = None,\n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"var_off\", \n",
    "#     # Mode:\n",
    "#     # \"universal\"  Uses the same variable for comparison\n",
    "#     # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "#     var_off=[\"gch\", \"gch\", \"gch\", \"gch\", \"gch\",\"kmsr50\", \"kms\", \"km5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, s in series:\n",
    "#     print(name)\n",
    "#     plt.hist(s, bins=40)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_comparison(\n",
    "#     dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "#     mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "#     var = None,\n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"var_off\", \n",
    "#     # Mode:\n",
    "#     # \"universal\"  Uses the same variable for comparison\n",
    "#     # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "#     var_off=[\"gch\", \"gch\", \"gch\", \"gch\", \"gch\",\"kmsr50\", \"kms\", \"km5\"], # A list of the same length as dfs and mnames\n",
    "#     metric=\"pearson\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With spearman ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"gch\", \"gch\", \"gch\", \"gch\",\"kmsr50\", \"kms_\", \"km5\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_comparison(\n",
    "#     dfs=[df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb],\n",
    "#     mnames=[\"SGNS\", \"NLI\", \"STS\", \"BIG\", \"KB\"],\n",
    "#     var=\"gch\", \n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"universal\", \n",
    "#     metric=\"pearson\"\n",
    "# ).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tight ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\", \"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"gch\", \"kms_\", \"km5\",\"kmsr50\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\", \"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"rch\", \"rch\", \"kms_\", \"km5\",\"kmsr50\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ").to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHY N=125 FOR GENUINE CHANGE?! Now fixed. \"kms_\" (underscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tigther...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_kb, df_cluster],\n",
    "    mnames = [\"SGNS\", \"KB\", \"KMS\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"gch\", \"kms_\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_kb, df_cluster],\n",
    "    mnames = [\"SGNS\", \"KB\", \"KMS\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"rch\", \"rch\", \"kms_\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tighter+**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets (shared):\n",
      "A1_globalistisk\n",
      "N1_berikare\n",
      "N1_frortsgng\n",
      "N1_globalist\n",
      "N1_kulturberikare\n",
      "N1_tervandring\n",
      "N2_tervandrare\n",
      "V1_berika\n",
      "V1_hjlpa_p_plats\n",
      "V1_kulturberika\n",
      "V1_tervandra\n",
      "Matrix-Size: 242 242 242 242 242\n",
      "Length (no NaN): 154 154 154 154 154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SGNS</th>\n",
       "      <th>SGNS*</th>\n",
       "      <th>KB</th>\n",
       "      <th>KB*</th>\n",
       "      <th>KMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGNS</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGNS*</th>\n",
       "      <td>0.679</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KB</th>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KB*</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMS</th>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SGNS  SGNS*     KB    KB*    KMS\n",
       "SGNS   1.000  0.679 -0.366  0.350 -0.038\n",
       "SGNS*  0.679  1.000 -0.293  0.582  0.111\n",
       "KB    -0.366 -0.293  1.000 -0.371  0.271\n",
       "KB*    0.350  0.582 -0.371  1.000  0.133\n",
       "KMS   -0.038  0.111  0.271  0.133  1.000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_yearly_dwt, df_bert_kb, df_bert_kb, df_cluster],\n",
    "    mnames = [\"SGNS\", \"SGNS*\", \"KB\", \"KB*\", \"KMS\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"rch\", \"gch\", \"rch\", \"kms_\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For LChange**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets (shared):\n",
      "A1_globalistisk\n",
      "N1_berikare\n",
      "N1_frortsgng\n",
      "N1_globalist\n",
      "N1_kulturberikare\n",
      "N1_tervandring\n",
      "N2_tervandrare\n",
      "V1_berika\n",
      "V1_hjlpa_p_plats\n",
      "V1_kulturberika\n",
      "V1_tervandra\n",
      "Matrix-Size: 242 242 242 242 242\n",
      "Length (no NaN): 154 154 154 154 154\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &   SGNS &  SGNS* &     KB &    KB* &    KMS \\\\\n",
      "\\midrule\n",
      "SGNS  &  1.000 &  0.679 & -0.366 &  0.350 & -0.038 \\\\\n",
      "SGNS* &  0.679 &  1.000 & -0.293 &  0.582 &  0.111 \\\\\n",
      "KB    & -0.366 & -0.293 &  1.000 & -0.371 &  0.271 \\\\\n",
      "KB*   &  0.350 &  0.582 & -0.371 &  1.000 &  0.133 \\\\\n",
      "KMS   & -0.038 &  0.111 &  0.271 &  0.133 &  1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_yearly_dwt, df_bert_kb, df_bert_kb, df_cluster],\n",
    "    mnames = [\"SGNS\", \"SGNS*\", \"KB\", \"KB*\", \"KMS\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"rch\", \"gch\", \"rch\", \"kms_\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ").to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Only in both Flashback and Familjeliv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets (shared):\n",
      "N1_globalist\n",
      "N1_kulturberikare\n",
      "N1_tervandring\n",
      "V1_berika\n",
      "V1_hjlpa_p_plats\n",
      "V1_kulturberika\n",
      "V1_tervandra\n",
      "Matrix-Size: 154 154 154 154 154\n",
      "Length (no NaN): 117 117 117 117 117\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &   SGNS &  SGNS* &  SBERT-PRT &  SBERT-PRT* &  SBERT-CLT \\\\\n",
      "\\midrule\n",
      "SGNS       &  1.000 &  0.721 &     -0.306 &       0.385 &      0.037 \\\\\n",
      "SGNS*      &  0.721 &  1.000 &     -0.239 &       0.601 &      0.137 \\\\\n",
      "SBERT-PRT  & -0.306 & -0.239 &      1.000 &      -0.383 &      0.290 \\\\\n",
      "SBERT-PRT* &  0.385 &  0.601 &     -0.383 &       1.000 &      0.126 \\\\\n",
      "SBERT-CLT  &  0.037 &  0.137 &      0.290 &       0.126 &      1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_yearly_dwt, df_bert_kb, df_bert_kb, df_cluster],\n",
    "    mnames = [\"SGNS\", \"SGNS*\", \"SBERT-PRT\", \"SBERT-PRT*\", \"SBERT-CLT\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts-both-in-fb-fm.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"gch\", \"rch\", \"gch\", \"rch\", \"kms_\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectified change (\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_comparison(\n",
    "#     dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "#     mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "#     var = None,\n",
    "#     norm=None, \n",
    "#     targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "#     prefix = (\"N\", \"A\", \"V\"),\n",
    "#     mode=\"var_off\", \n",
    "#     # Mode:\n",
    "#     # \"universal\"  Uses the same variable for comparison\n",
    "#     # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "#     var_off=[\"rch\", \"rch\", \"rch\", \"rch\", \"rch\",\"kmsr50\", \"kms\", \"km5\"], # A list of the same length as dfs and mnames\n",
    "#     metric=\"pearson\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"rch\", \"rch\", \"rch\", \"rch\", \"rch\",\"kmsr50\", \"kms\", \"km5\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tighter set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_sts, df_bert_kb, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\",  \"STS\",\"KB\", \"KMS\", \"KM5\",\"KMSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"rch\", \"rch\", \"rch\",\"kms\", \"km5\", \"kmsr50\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding ACS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [df_yearly_dwt, df_bert_nli, df_bert_sts, df_bert_big, df_bert_kb, df_cluster, df_cluster, df_cluster, df_cluster, df_cluster, df_cluster],\n",
    "    mnames = [\"SGNS\", \"NLI\",  \"STS\",\"BIG\",\"KB\", \"KMS\", \"KM5\", \"KM15\", \"KMSR50\", \"ACS\", \"ACSR50\"],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\"rch\", \"rch\", \"rch\", \"rch\", \"rch\", \"kms\", \"km5\", \"km15\",\"kmsr50\", \"acs\", \"acsr50\"], # A list of the same length as dfs and mnames\n",
    "    metric=\"pearson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(\n",
    "    dfs = [\n",
    "        df_yearly_dwt, \n",
    "        df_bert_kb, \n",
    "        df_cluster,\n",
    "        df_cluster, \n",
    "        df_cluster,\n",
    "        df_yearly_ref_dwt, \n",
    "        df_bert_kb_ref, \n",
    "        df_cluster_ref,\n",
    "        df_cluster_ref, \n",
    "        df_cluster_ref        \n",
    "    ],\n",
    "    mnames = [\n",
    "        \"SGNS\", \n",
    "        \"KB\", \n",
    "        \"KMS\", \n",
    "        \"KM5\",\n",
    "        \"KMSR50\",\n",
    "        \"SGNS-ref\", \n",
    "        \"KB-ref\", \n",
    "        \"KMS-ref\", \n",
    "        \"KM5-ref\",\n",
    "        \"KMSR50-ref\"        \n",
    "    ],\n",
    "    var = None,\n",
    "    norm=None, \n",
    "    targets = Path(\"../data/utils/dwts.txt\"), # =get_dwts(df_yearly_dwt, dwt_path)\n",
    "    prefix = (\"N\", \"A\", \"V\"),\n",
    "    mode=\"var_off\", \n",
    "    # Mode:\n",
    "    # \"universal\"  Uses the same variable for comparison\n",
    "    # \"var_off\"    Uses different variables for different models. Obs! Do not forget to normalize!\n",
    "    var_off=[\n",
    "        \"rch\", \n",
    "        \"rch\",\n",
    "        \"kms\", \n",
    "        \"km5\",\n",
    "        \"kmsr50\",\n",
    "        \"rch\", \n",
    "        \"rch\",\n",
    "        \"kms\", \n",
    "        \"km5\",\n",
    "        \"kmsr50\"\n",
    "    ], # A list of the same length as dfs and mnames\n",
    "    col_start = 2003,\n",
    "    metric=\"pearson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TERMS THAT CHANGE THE MOST (OVERALL) - ONLY SGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Proper Nouns! (cf. REFERENCE)\n",
    "* Non-Swedish words\n",
    "* DWTs are among the most changing words:\n",
    "    * \"N1_kulturberikare\", rank 25 in 2009-2010\n",
    "    * \"N1_tervandring\", rank 6 in 2017-2018 and rank 29 in 2018-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_show(df_yearly, \"rch\", as_table = True, min_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_show(df_yearly, \"gch\", as_table = True, min_freq=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging ... (obsolete)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ncd(DATA=df_yearly, CORPUS=corpus, VAR=\"gsim\", VAL=1.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w_overlap_checker(corpus=corpus, th_c=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checker(\n",
    "    word=\"gyllene\", \n",
    "    transition=(2000,2001), \n",
    "    controls_dir=\"/home/max/Results/fb_pol-yearly-rad3\", \n",
    "    n_ctrl=10, \n",
    "    variable=\"cosine_change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four year time bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No DWTs among top terms\n",
    "* Clearly influenced by important events and reflects the public agenda: \n",
    "    * Crimea invasion (2007:2011)\n",
    "    * Begging ('tiggeri') (2007:2011)\n",
    "    * US President election (2011:2015)\n",
    "    * COVID-19 (2015:2019)\n",
    "    * Russian invation of Ukraine (2015:2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#q_show(df_tbn, \"rch\", as_table = True, min_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_show(df_tbn, \"gch\", as_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOG WHISTLE TERMS: CHANGE DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YEARLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six cases of \"sign.\" change:\n",
    "* N1_berikare (06:07)\n",
    "* N1_globalist (07:08)\n",
    "* N1_kulturberikare (06:07, 09:10) \n",
    "* N1_tervandring (17:18, 18:19)\n",
    "\n",
    "Note that the \"old\" DW of \"enrichment\" mostly changes in the early years (N1_berikare, N1_kulturberikare). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_yearly_dwt, \"rch\", DWTs, return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_yearly_dwt, \"rch\", DWTs, th=2.821, return_md=True) # Alpha = 0.01\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- Save to file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#_ = overview(df_yearly_dwt, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "when = overview(df_yearly_dwt, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/sgns-yearly-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**46** cases of \"sign.\" change. That is almost ten times as many as for SGNS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=2.821, return_md=True) # Alpha = 0.01\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  --- Save to file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "when = overview(df_bert_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/sts-yearly-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_bert_kb, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_bert_kb, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=2.821, return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "when = overview(df_bert_kb, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/kb-yearly-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(df_yearly_ref_dwt, \"rch\", get_dwts(df_yearly_ref_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "when = overview(df_yearly_ref_dwt, \"rch\", get_dwts(df_yearly_ref_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/sgns_ref-yearly-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = overview(df_bert_kb_ref, \"rch\", get_dwts(df_yearly_ref_dwt, dwt_path), return_md=True)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "when = overview(df_bert_kb_ref, \"rch\", get_dwts(df_yearly_ref_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/kb_ref-yearly-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAYERED SYUMMARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layered_view(\n",
    "    [\n",
    "        overview(df_yearly_dwt, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_bert_kb, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_cluster, \"p_kms_\", DWTs, th=0.0005, reverse_th=True, return_complex=True)\n",
    "    ],\n",
    "    #ignore_pos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layered_view(\n",
    "    [\n",
    "        overview(df_yearly_dwt, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_bert_kb, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_cluster, \"p_kmsr50\", DWTs, th=0.0005, reverse_th=True, return_complex=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heated_layer(\n",
    "    [\n",
    "        overview(df_yearly_dwt, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_bert_kb, \"rch\", DWTs, th=4.781, return_complex=True), \n",
    "        overview(df_cluster, \"p_kms_\", DWTs, th=0.0005, reverse_th=True, return_complex=True)\n",
    "    ],\n",
    "    ignore_pos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Y-TIME BINS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Despite there are fewer transitions in the time bin experiment, there are more cases of \"sign.\" changes detected. Compared with the yearly experiment, the verbs \"berika\" and \"tervandra\" are identified as changing.\n",
    "* There is no change in 07:11. **Why?** *The need of validation!*\n",
    "* The \"berika\" vocabulary mostly changes in the early years (N1_berikare, N1_kulturberikare, V1_berika, V1_kulturberika) although N1_kulturberikare and V1_berika also changes in 11:15.\n",
    "\n",
    "For reference here (from above):\n",
    "\n",
    "    N1_berikare (06:07)\n",
    "    N1_globalist (07:08)\n",
    "    N1_kulturberikare (06:07, 09:10)\n",
    "    N1_tervandring (17:18, 18:19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = overview(df_tbn_dwt, \"rch\", get_dwts(df_tbn_dwt, dwt_path), return_md=True)\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering only terms with min. freq. of 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# _ = overview(df_tbn_dwt, \"rch\", get_dwts(df_tbn_dwt, dwt_path), return_md=True, min_freq=100)\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- Save to file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "when = overview(df_tbn_dwt, \"rch\", get_dwts(df_tbn_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/sgns-tbn-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, more significiant transtitions (i.e. RCH > 4.781) for BERT than for SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _ = overview(df_tbn_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), return_md=True)\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum freq. of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _ = overview(df_tbn_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), min_freq=100, return_md=True)\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --- Save to file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "when = overview(df_tbn_sts, \"rch\", get_dwts(df_yearly_dwt, dwt_path), th=None, return_md=False)\n",
    "when.to_csv(\"../../dw_results/change_tables/sts-tbn-change.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#q_show(df_time_bin, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_show(df_tbn_sts, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change_show(df_tbn_sts, \"rch\", get_dwts(df_tbn_sts, dwt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOG WHISTLE TERMS: SPREAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trending?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note-to-self:** Is `trend()` really reliable? What's going on with `NaN`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N1_frortsgng is the only term with a sign. trend over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trend(df_bert_sts, var=\"spr\", norm=None, transition = False, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is spread related to change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No**, not in general, but there is a positive relationship between `log(divspr)` and GCH. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genuine change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"difspr\", \n",
    "    var2 = \"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"spearman\",\n",
    "    top_n = None,\n",
    "    #min_freq = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"divspr\", \n",
    "    var2 = \"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = None,\n",
    "    #min_freq = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectified change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No association. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"difspr\", \n",
    "    var2 = \"rch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"spearman\",\n",
    "    top_n = None,\n",
    "    #min_freq = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"divspr\", \n",
    "    var2 = \"rch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = None,\n",
    "    #min_freq = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize(df_bert_sts, \"--ALL\", \"spr\", prefix = (\"N\", \"A\", \"V\"), transition=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ... the same as z-scores\n",
    "#visualize(df_bert_sts, \"--ALL\", \"zscspr\", prefix = (\"N\", \"A\", \"V\"), transition=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomaly spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize(df_bert_sts, \"--ALL\", \"anospr\", prefix = (\"N\", \"A\", \"V\"), transition=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly spread in numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = overview(\n",
    "    df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    \"anospr\", \n",
    "    get_dwts(df_bert_sts, dwt_path), \n",
    "    th=None, \n",
    "    transition = False, \n",
    "    min_freq = None, \n",
    "    return_md=True, \n",
    "    rounder = 2)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = overview(df_bert_sts, \"anospr\", get_dwts(df_bert_sts, dwt_path), th=-2, transition = False, min_freq = None, return_md=True, rounder = 2)\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend(df_bert_sts, var=\"anospr\", norm=None, transition = False, metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is spread related to frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher frequency means higher spread, which makes sense (not a strong correlation though)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"fpm\", \n",
    "    var2 = \"spr\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = np.log,\n",
    "    prenorm2 = None,\n",
    "    norm1=zscore, \n",
    "    norm2=zscore, \n",
    "    metric=\"pearson\",\n",
    "    top_n = None,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, when considering all terms and the *difference* of frequency and spread at each transition, there is *no* correlation. That is, the *change* in frequency is unrelated to the *change* in spread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1 = \"divfpm\", \n",
    "    var2 = \"difspr\", \n",
    "    var1cut = None, \n",
    "    var2cut = None,\n",
    "    prenorm1 = np.log, #  <-- Obs!\n",
    "    prenorm2 = None,\n",
    "#     norm1=zscore, \n",
    "#     norm2=zscore, \n",
    "    metric=\"pearson\",\n",
    "    top_n = None,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is some variability here. For the terms \"N1_kulturberikare\" and \"V1_kulturberika\", increase in frequency means decrease in spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [t for t in DWTs if t.startswith((\"N\", \"A\", \"V\"))]:\n",
    "    try:\n",
    "        score = universal_correlation(\n",
    "            df = df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith(t)],:], \n",
    "            var1 = \"divfpm\", \n",
    "            var2 = \"difspr\", \n",
    "            var1cut = None, \n",
    "            var2cut = None,\n",
    "            prenorm1 = np.log,\n",
    "            prenorm2 = None,\n",
    "            norm1=zscore, \n",
    "            norm2=zscore, \n",
    "            metric=\"pearson\",\n",
    "            top_n = None,\n",
    "            min_freq = None,\n",
    "            verbose = False\n",
    "        )\n",
    "    except ValueError:\n",
    "        score = \"Something went wrong!\"\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "        var1=\"fpm\", \n",
    "        var1tr = False,\n",
    "        var2=\"spr\",\n",
    "        var2tr = False,\n",
    "        prenorm1=np.log,\n",
    "        norm1=zscore,\n",
    "        norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW IS MEANING CHANGE RELATED TO FREQUENCY?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Can we confirm a *law of confirmity*? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** In this section overall (SGNS only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt. 1: a failed attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all data - all words (not only DWTs) - we find the opposite to the law of confirmity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spearman... (without `log(frequency)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive (0.47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pearson, with log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive (0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt. 2: replicating Hamilton et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mystery solved!* Hamilton et al only considers the top 10 000 words. This confirms the law of confirmity - *for genuine change*. Note much weaker correlation here, than in Hamilton et al. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General conclusion: the law of confirmity only holds for the most frequent words of the vocabulary. Considering less frequent words (e.g. by considering a larger proportion of the total vocabulary), the law is reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cut last**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"spearman\", #<-- Obs!\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\", #<-- Obs!\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=np.log, # <-- Obs!\n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\", # <-- Obs!\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explains (only) 6,7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "0.26*0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"OLS\",\n",
    "    top_n =10000,\n",
    "    #top_cut_off = 10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a mess ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 10000,\n",
    "    min_freq = None,\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cut first**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower effect, less explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = 0, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\",\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"divfpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\",\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"divfpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"OLS\",\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"divfpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 10000,\n",
    "    min_freq = None,\n",
    "    alpha=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_yearly.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT NOT SO FAST ...** \n",
    "The relationship is not linear. Consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Top *k* from 1000 to 100 000 increased by *i* - not linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step = 1000\n",
    "Ns = list(range(1000, 70000, step))\n",
    "my_rs = []\n",
    "\n",
    "for i, N in enumerate(Ns):\n",
    "    print(f\"{i} of {len(Ns)}\", end=\"\\r\")\n",
    "    r = universal_correlation(\n",
    "        df=df_yearly, \n",
    "        var1=\"fpm\", \n",
    "        var2=\"gch\", \n",
    "        var1cut = 0, \n",
    "        var2cut = None, \n",
    "        norm1=np.log, \n",
    "        norm2=None, \n",
    "        metric=\"spearman\",\n",
    "        top_n =N,\n",
    "        #top_cut_off=N-step, # <--- Obs!\n",
    "        min_freq = None\n",
    "    )\n",
    "    my_rs.append(r[0])\n",
    "\n",
    "#print(my_rs)\n",
    "#print(Ns)\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=300)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.xlabel(\"Top $N$ words included\")\n",
    "plt.ylabel(\"Correlation of naive cosine change and fpm (at $t_i$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5), dpi=300)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.xlabel(\"Top $N$ words included\")\n",
    "plt.ylabel(\"Correlation of naive cosine change and fpm (at $t_i$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So re-consider top 5000; Now almost 10% explained by frequency of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n =5000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.31*0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"OLS\",\n",
    "    top_n =5000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But still looks kind of messy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 5000,\n",
    "    min_freq = None,\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spans from (k-500, k)\n",
    "\n",
    "Clearly (a) not linear, (b) *not* negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1000\n",
    "Ns = list(range(1000, 100000, step))\n",
    "my_rs = []\n",
    "\n",
    "for N in Ns:\n",
    "    r = universal_correlation(\n",
    "        df=df_yearly, \n",
    "        var1=\"fpm\", \n",
    "        var2=\"gch\", \n",
    "        var1cut = 0, \n",
    "        var2cut = None, \n",
    "        norm1=np.log, \n",
    "        norm2=None, \n",
    "        metric=\"pearson\",\n",
    "        top_n =N,\n",
    "        top_cut_off=N-step, # <-- Obs!\n",
    "        min_freq = None,\n",
    "        verbose=False\n",
    "    )\n",
    "    my_rs.append(r[0])\n",
    "\n",
    "print(my_rs)\n",
    "print(Ns)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check a span for k = (5000, 10 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n =10000,\n",
    "    top_cut_off=5000,\n",
    "    #top_cut_off=100,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = 0, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 5000,\n",
    "    top_cut_off = 100,\n",
    "    min_freq = None,\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt. 3: replicating Dubossarsky et al. (kind of)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that, the law of confirmity does *not* hold for RCH; compare Dubossarsky et al. Rather, more frequent terms change *more*! Note that Dubossarsky et al. makes a \"weaker\" claim, namely that law of confirmity is (much) less prominent when controling for variability, but here we find a significant correaltion for the opposite of the law of confirmity. Perhaps, a regression model should be built here to make the results fully comparable with Dubossarksy et al. and Hamilton et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, # cut last\n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"pearson\",\n",
    "    top_n =10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, # cut last\n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    metric=\"spearman\",\n",
    "    top_n =10000,\n",
    "    min_freq = None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"rch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 10000,\n",
    "    min_freq = None,\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly, \n",
    "    var1=\"fpm\", \n",
    "    var2=\"rch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 5000,\n",
    "    min_freq = None,\n",
    "    alpha=0.3,\n",
    "    ymax=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 1000\n",
    "Ns = list(range(1000, 70000, step))\n",
    "my_rs = []\n",
    "\n",
    "for i, N in enumerate(Ns):\n",
    "    print(f\"{i} of {len(Ns)}\", end = \"\\r\")\n",
    "    r = universal_correlation(\n",
    "        df=df_yearly, \n",
    "        var1=\"fpm\", \n",
    "        var2=\"rch\", \n",
    "        var1cut = 0, \n",
    "        var2cut = None, \n",
    "        norm1=np.log, \n",
    "        norm2=None, \n",
    "        metric=\"spearman\",\n",
    "        top_n =N,\n",
    "        #top_cut_off=N-step,\n",
    "        min_freq = None,\n",
    "        verbose=False\n",
    "    )\n",
    "    my_rs.append(r[0])\n",
    "\n",
    "#print(my_rs)\n",
    "#print(Ns)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6), dpi=300)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.xlabel(\"fpm (at $t_i$)\")\n",
    "plt.ylabel(\"Correlation of rectified change and fpm (at $t_i$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 1000\n",
    "Ns = list(range(1000, 100000, step))\n",
    "my_rs = []\n",
    "\n",
    "for N in Ns:\n",
    "    r = universal_correlation(\n",
    "        df=df_yearly, \n",
    "        var1=\"fpm\", \n",
    "        var2=\"rch\", \n",
    "        var1cut = 0, \n",
    "        var2cut = None, \n",
    "        norm1=np.log, \n",
    "        norm2=None, \n",
    "        metric=\"pearson\",\n",
    "        top_n =N,\n",
    "        top_cut_off=N-step,\n",
    "        min_freq = None,\n",
    "        verbose=False\n",
    "    )\n",
    "    my_rs.append(r[0])\n",
    "\n",
    "print(my_rs)\n",
    "print(Ns)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt. 4: Some other frequency based correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Does difference in frequency  explain change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note a very strong correlation between `diffpm` and `divfpm` (spearman). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_yearly,\n",
    "    var1 = \"diffpm\", \n",
    "    var2 = \"divfpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None,\n",
    "    #top_n = 10000,\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yes**, to some extent: *increase* in frequency is pos. correlated with (rectified) change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_yearly,\n",
    "    var1 = \"divfpm\", \n",
    "    var2 = \"rch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None,\n",
    "    top_n = 10000,\n",
    "    metric=\"pearson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df = df_yearly,\n",
    "    var1 = \"diffpm\", \n",
    "    var2 = \"rch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None,\n",
    "    top_n = 10000,\n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GCH x RCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCH and GCH are pos. correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    #top_n = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"spearman\", # <-- Obs!\n",
    "    top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Towards a better understanding of the components of RCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RCH x Std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"stdc\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly, \n",
    "    var1=\"rch\", \n",
    "    var2=\"stdc\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    #top_n = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. DWTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranks and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"tot_frq\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ranks = df_yearly.copy()\n",
    "my_ranks[\"rank\"] = my_ranks[\"tot_frq\"].rank(method=\"average\", ascending=False)\n",
    "my_ranks.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"rank\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ranks[\"rank\"] = my_ranks[\"tot_frq\"].rank(method=\"min\", ascending=False)\n",
    "my_ranks.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"rank\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_ranks[\"rank\"] = my_ranks[\"tot_frq\"].rank(method=\"max\", ascending=False)\n",
    "my_ranks.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"rank\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = my_ranks[\"tot_frq\"].rank(method=\"min\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pd.concat(\n",
    "    [\n",
    "        df_yearly.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"tot_frq\"],\n",
    "        my_ranks.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:][\"rank\"],\n",
    "        correlation(\n",
    "            df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\",\n",
    "            var2=\"gch\", \n",
    "            mode=2,\n",
    "            varcutter=True, # Cuts var1\n",
    "            norm1=np.log, \n",
    "            metric=\"spearman\"\n",
    "        ).set_index('Word').rename(columns={\"Correlation\": r\"$\\rho$, A1: naive\"}),\n",
    "        correlation(\n",
    "            df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\",\n",
    "            var2=\"rch\", \n",
    "            mode=2,\n",
    "            varcutter=True, # Cuts var1\n",
    "            norm1=np.log, \n",
    "            metric=\"spearman\"\n",
    "        ).set_index('Word').rename(columns={\"Correlation\": r\"$\\rho$, A1:, rect.\"}),\n",
    "        correlation(\n",
    "            df=df_bert_kb.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\",\n",
    "            var2=\"gch\", \n",
    "            mode=2,\n",
    "            varcutter=True, # Cuts var1\n",
    "            norm1=np.log, \n",
    "            metric=\"spearman\"\n",
    "        ).set_index('Word').rename(columns={\"Correlation\": r\"$\\rho$, A2: naive\"}), \n",
    "        correlation(\n",
    "            df=df_bert_kb.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\",\n",
    "            var2=\"rch\", \n",
    "            mode=2,\n",
    "            varcutter=True, # Cuts var1\n",
    "            norm1=np.log, \n",
    "            metric=\"spearman\"\n",
    "        ).set_index('Word').rename(columns={\"Correlation\": r\"$\\rho$, A2: rect\"}),         \n",
    "        correlation(\n",
    "            df=df_cluster.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\",\n",
    "            var2=\"kms\", \n",
    "            mode=2,\n",
    "            varcutter=True, # Cuts var1\n",
    "            norm1=np.log, \n",
    "            metric=\"spearman\"\n",
    "        ).set_index('Word').rename(columns={\"Correlation\": r\"$\\rho$, A3 (kms): jsd\"}), \n",
    "        \n",
    "    ], axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U.to_csv(\"../../../frqxchg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RCH x GCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_bert_kb.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N1\", \"N2\" \"A\", \"V1\"))],:], \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    #top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_bert_sts.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N1\", \"N2\" \"A\", \"V\"))],:], \n",
    "    var1=\"rch\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\",\n",
    "    top_n = 10000     # <-- Obs!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. SGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now turning to DWTs and the relationship between frequency and change, we can first conclude that these terms violates the law of confirmity; both considering RCH and GCH. **In general, the terms change more the more frequent they become.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENUINE change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (Cut the last one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "#                      \"fpm\", \n",
    "#                      \"gch\", \n",
    "#                      -1, \n",
    "#                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                     metric=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                     metric=\"OLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    #top_n = 10000,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: Add color to this one! Would clarify the relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency is an \"interaction term\" of the relationship. Compare the two most frequent terms with the less frequent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top_n = 2 (globalist, berika)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly_dwt, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 2,\n",
    "    #top_cut_off=3,\n",
    "    min_freq = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4764**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      top_n=2,\n",
    "                      norm1=np.log,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 2,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the third dimension! top_n \n",
    "vis_u_cor_with_labels(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    #top_n = 10000,\n",
    "    min_freq = None, \n",
    "    alpha=1,\n",
    "    group = [[\"N1_globalist\", \"V1_berika\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly_dwt, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 1,\n",
    "    #top_cut_off=3,\n",
    "    min_freq = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7905947**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      top_n=1,\n",
    "                      norm1=np.log,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 1,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span (3, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span (3, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly_dwt, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 1000,\n",
    "    top_cut_off=3,\n",
    "    min_freq = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6050**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      top_n=1000,\n",
    "                      top_cut_off=3,\n",
    "                      norm1=np.log,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 10000,\n",
    "    top_cut_off=3,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Span (2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    df=df_yearly_dwt, \n",
    "    var1=\"gch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = -1, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 1000,\n",
    "    top_cut_off=2,\n",
    "    min_freq = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      top_n=1000,\n",
    "                      top_cut_off=2,\n",
    "                      norm1=np.log,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"gch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    top_n = 10000,\n",
    "    top_cut_off=2,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cut the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "#                      \"fpm\", \n",
    "#                      \"gch\", \n",
    "#                      0, \n",
    "#                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\",\n",
    "    var2=\"gch\", \n",
    "    mode=2,\n",
    "    varcutter=True, # Cuts var1\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\"\n",
    ").sort_values(by=\"Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"gch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RECTIFIED change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "#                      \"fpm\", \n",
    "#                      \"rch\", \n",
    "#                      0, \n",
    "#                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1, \n",
    "                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1, \n",
    "                      #top_n=2,\n",
    "                      norm1=np.log,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"rch\", \n",
    "    var1cut = -1, \n",
    "    var2cut = None, \n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    #top_n = 10000,\n",
    "    min_freq = None, \n",
    "    alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 2 etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      1,\n",
    "                      top_n=1,\n",
    "                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1,\n",
    "                      top_n=100,\n",
    "                      top_cut_off=3,\n",
    "                      norm1=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most terms, frequency and RCH are unrelated. In comparison with GCH, we see that this \"contra-pattern\" is much stronger for RCH than for GCH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\",\n",
    "    var2=\"rch\", \n",
    "    mode=2,\n",
    "    varcutter=True, # Cuts var1\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\"\n",
    ").sort_values(by=\"Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"rch\", \n",
    "    var1tr = False, \n",
    "    var2tr = True, \n",
    "    prenorm1 = np.log,\n",
    "    prenorm2 = None,\n",
    "    norm1=zscore,\n",
    "    norm2=zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GCH x RCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a (strong) pos. correl. for RCH and GCH ... but it is related to frequency, since postive correlation diminishes and eventually disappears when considering the 100, 1000 most frequent DWTs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(\n",
    "    df=df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    var1=\"gch\",\n",
    "    var2=\"rch\", \n",
    "    mode=2,\n",
    "    #varcutter=True, # Cuts var1\n",
    "    prenorm1 = None,\n",
    "    prenorm2 = None,\n",
    "    #norm1=np.log, \n",
    "    norm2=None, \n",
    "    metric=\"pearson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"gch\", \n",
    "                      \"rch\", \n",
    "                      #min_freq=10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"gch\", \n",
    "                      \"rch\", \n",
    "                      top_n=1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"gch\", \n",
    "                      \"rch\", \n",
    "                      min_freq=100\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq=1000                     \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rs=[]\n",
    "step=100\n",
    "Ns = range(0, 2000, step)\n",
    "for N in Ns:\n",
    "    r, _ = universal_correlation(df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "                      \"gch\", \n",
    "                      \"rch\", \n",
    "                      #norm1=np.log,\n",
    "                      min_freq=N,\n",
    "                      verbose=False\n",
    "                     )\n",
    "    my_rs.append(r)\n",
    "plt.scatter(Ns, my_rs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference of frequency x RCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, increased frequencey means more change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `diffpm` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman (no log; we cannot do logs on negative numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "    #df = df_bert_big.loc[[w for w in df_bert_sts.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "    df = df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:],\n",
    "    var1 = \"diffpm\", \n",
    "    var2 = \"rch\", \n",
    "    var1cut = None, \n",
    "    var2cut = None, \n",
    "    norm1=None, \n",
    "    norm2=None, \n",
    "    metric=\"spearman\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `divfpm` (with `log`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "            df = df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith((\"N\", \"A\", \"V\"))],:], \n",
    "            var1 = \"divfpm\", \n",
    "            var2 = \"rch\", \n",
    "            var1cut = None, \n",
    "            var2cut = None,\n",
    "            prenorm1 = np.log,\n",
    "            prenorm2 = None,\n",
    "            #norm1=zscore, \n",
    "            #norm2=zscore, \n",
    "            metric=\"pearson\",\n",
    "            top_n = None,\n",
    "            min_freq = None,\n",
    "            verbose = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but this does not hold for every term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in [t for t in DWTs if t.startswith((\"N\", \"A\", \"V\"))]:\n",
    "    try:\n",
    "        score = universal_correlation(\n",
    "            df = df_yearly_dwt.loc[[w for w in df_yearly_dwt.index if w.startswith(t)],:], \n",
    "            var1 = \"divfpm\", \n",
    "            var2 = \"rch\", \n",
    "            var1cut = None, \n",
    "            var2cut = None,\n",
    "            prenorm1 = np.log,\n",
    "            prenorm2 = None,\n",
    "            #norm1=zscore, \n",
    "            #norm2=zscore, \n",
    "            metric=\"pearson\",\n",
    "            top_n = None,\n",
    "            min_freq = None,\n",
    "            verbose = False\n",
    "        )\n",
    "    except ValueError:\n",
    "        score = \"Something went wrong!\"\n",
    "    print(t, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run pearson with only positive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(\n",
    "            df = df_yearly_dwt.loc[[\"N1_kulturberikare\", \"N1_berikare\", \"V1_kulturberika\", \"N1_tervandring\", \"V1_tervandra\"],:], \n",
    "            var1 = \"divfpm\", \n",
    "            var2 = \"rch\", \n",
    "            var1cut = None, \n",
    "            var2cut = None,\n",
    "            prenorm1 = np.log,\n",
    "            prenorm2 = None,\n",
    "            #norm1=zscore, \n",
    "            #norm2=zscore, \n",
    "            metric=\"pearson\",\n",
    "            top_n = None,\n",
    "            min_freq = None,\n",
    "            verbose = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2(a). KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENUINE: law of confirmity confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... cut last & Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric=\"spearman\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly violates the assumptions of linear regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var2=\"gch\", \n",
    "            varcutter=True,\n",
    "            norm1 = np.log,\n",
    "            mode=2, \n",
    "            metric = \"spearman\").sort_values(by=\"Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"gch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_cor(\n",
    "    df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\" \"A1_\", \"V1_\", \"P1_\"))],:], \n",
    "    var1=\"fpm\", \n",
    "    var2=\"rch\", \n",
    "    var1tr = False, \n",
    "    var2tr = True, \n",
    "    prenorm1 = np.log,\n",
    "    prenorm2 = None,\n",
    "    norm1=zscore,\n",
    "    norm2=zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RECTIFIED: opposite relationship to that of GCH (and law of c.): positive correlation; if at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric=\"spearman\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric=\"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "        var1=\"fpm\", \n",
    "        var1tr = False,\n",
    "        var2=\"rch\",\n",
    "        prenorm1=np.log,\n",
    "        norm1=zscore,\n",
    "        norm2=zscore,\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference in freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"divfpm\", \n",
    "                      \"rch\", \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, no sign. relationship for:\n",
    "* V1_berika\n",
    "* V1_kulturberika\n",
    "* N1_frortsgng\n",
    "* A1_globalistisk (p = 0.05)\n",
    "* V1_hjlpa_p_plats\n",
    "* N2_tervandrare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var2=\"rch\", \n",
    "            varcutter=True,\n",
    "            norm1 = np.log,\n",
    "            mode=2, \n",
    "            metric = \"pearson\").sort_values(by=\"Word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_kb.loc[[w for w in df_bert_kb.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"rch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_bert_kb, \n",
    "    var1=\"rch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = 0, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 10000,\n",
    "    min_freq = None, \n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u_cor(\n",
    "    df=df_bert_kb, \n",
    "    var1=\"rch\", \n",
    "    var2=\"fpm\", \n",
    "    var1cut = None, \n",
    "    var2cut = 0, \n",
    "    norm1=None, \n",
    "    norm2=np.log, \n",
    "    top_n = 10000,\n",
    "    min_freq = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2(a). STS (small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Confirms *law of confirmity* for GCH. \n",
    "* The effect disappears with RCH; compare Duborssarsky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENUINE: law of confirmity confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... cut first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... cut last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"gch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var2=\"gch\", \n",
    "            varcutter=True,\n",
    "            norm1 = np.log,\n",
    "            mode=2, \n",
    "            metric = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"gch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_cor(\n",
    "    df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\" \"A1_\", \"V1_\", \"P1_\"))],:], \n",
    "    var1=\"rch\", \n",
    "    var2=\"fpm\", \n",
    "    var1tr = True, \n",
    "    var2tr = False, \n",
    "    prenorm1 = None,\n",
    "    prenorm2 = np.log,\n",
    "    norm1=zscore,\n",
    "    norm2=zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RECTIFIED: opposite relationship to that of GCH (and law of c.): positive correlation; if at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      0, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"rch\", \n",
    "                      -1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"rch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difference in freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"divfpm\", \n",
    "                      \"rch\", \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Per term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, no sign. relationship for:\n",
    "* V1_berika\n",
    "* V1_kulturberika\n",
    "* N1_frortsgng\n",
    "* A1_globalistisk (p = 0.05)\n",
    "* V1_hjlpa_p_plats\n",
    "* N2_tervandrare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var2=\"rch\", \n",
    "            varcutter=True,\n",
    "            norm1 = np.log,\n",
    "            mode=2, \n",
    "            metric = \"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_cor(df=df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "            var1=\"fpm\", \n",
    "            var1tr = False,\n",
    "            var2=\"rch\",\n",
    "            prenorm1=np.log,\n",
    "            norm1=zscore,\n",
    "            norm2=zscore\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Final notes on Std., means and RCH X GCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the standard deviation, the larger RCH. As expected, since RCH is defined in those terms, but RCH is not strongly nor positively correlated with GCH! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"stdc\", \n",
    "                      \"rch\", \n",
    "                      norm1=None,\n",
    "                      min_freq = 100\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the control mean, the larger RCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"mccc\", \n",
    "                      \"rch\", \n",
    "                      norm1=None,\n",
    "                      min_freq = 100\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the SGNS models, RCH and GCH are *poorly* correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_bert_sts.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"gch\", \n",
    "                      \"rch\", \n",
    "                      norm1=None,\n",
    "                      min_freq = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCH with somtimes very small GCH; consider esp. from 2006 onwards (V1_berika, N1_berikare, N1_globalist, N1_tervandring, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_show(df_bert_sts, \"rch\", as_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENUINE: law of confirmity confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... cut last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_cluster.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"kms\", \n",
    "                      1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric = \"pearson\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_cluster.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"kms\", \n",
    "                      1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric = \"spearman\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_correlation(df_cluster.loc[[w for w in df_bert_sts.index if w.startswith((\"N1_\", \"N2_\", \"A1_\", \"V1_\"))],:], \n",
    "                      \"fpm\", \n",
    "                      \"kms\", \n",
    "                      1, \n",
    "                      norm1=np.log,\n",
    "                      min_freq = 11,\n",
    "                      metric = \"OLS\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
