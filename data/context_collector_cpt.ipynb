{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Collector - Context per Term (CPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_root = Path(\"/home/max/Corpora/flashback-pol-time/yearly/contexts/vectors/\")\n",
    "ctx_root = Path(\"/home/max/Corpora/flashback-pol-time/yearly/contexts/files/\")\n",
    "vpt_root = Path(\"/home/max/Corpora/flashback-pol-time/yearly/contexts_per_term/vectors/\")\n",
    "xpt_root = Path(\"/home/max/Corpora/flashback-pol-time/yearly/contexts_per_term/files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find terms\n",
    "terms = set()\n",
    "for directory in os.listdir(vec_root):\n",
    "    for file in os.listdir(vec_root / directory):\n",
    "        with open(vec_root / directory / file) as f:\n",
    "            for line in f:\n",
    "                term, _ = tuple(line.strip(\"\\n\").split(\"\\t\"))\n",
    "                terms.add(term)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1_globalistisk',\n",
       " 'N1C_berikareX',\n",
       " 'N1C_förortsgängX',\n",
       " 'N1C_globalistX',\n",
       " 'N1C_kulturberikarX',\n",
       " 'N1C_återvandringsX',\n",
       " 'N1_berikare',\n",
       " 'N1_förortsgäng',\n",
       " 'N1_globalist',\n",
       " 'N1_kulturberikare',\n",
       " 'N1_återvandring',\n",
       " 'N2C_återvandrarX',\n",
       " 'N2_återvandrare',\n",
       " 'P1_ordning_och_reda_i_flyktingpolitiken',\n",
       " 'P1_självständig_utrikespolitik',\n",
       " 'V1_berika',\n",
       " 'V1_hjälpa_på_plats',\n",
       " 'V1_kulturberika',\n",
       " 'V1_återvandra',\n",
       " 'V2_hjälpa_X_på_plats',\n",
       " 'X_berika',\n",
       " 'X_globalist',\n",
       " 'X_hjälpa \" dem i sitt närområde , på plats',\n",
       " 'X_hjälpa de lidande , de krigsskadade och de nödställda på plats',\n",
       " 'X_hjälpa dem att bygga upp välfungerande samhällen , på plats',\n",
       " 'X_hjälpa dem att fastställa huruvida förbjudna giftiga vapen ska ha använts på plats',\n",
       " 'X_hjälpa dem att få sommarjobb på plats',\n",
       " 'X_hjälpa dem på plats',\n",
       " 'X_hjälpa den på plats',\n",
       " 'X_hjälpa en liten kvot ( den kvot som faktiskt flyr från krig och svält ) för att sen fokusera på plats',\n",
       " 'X_hjälpa flest genom att hjälpa på plats',\n",
       " 'X_hjälpa flyktingar på plats',\n",
       " 'X_hjälpa folk på plats',\n",
       " 'X_hjälpa mena folket på plats',\n",
       " 'X_hjälpa många fler på plats',\n",
       " 'X_hjälpa mångfalden på traven genom att exempelvis offra getter och grisar på plats',\n",
       " 'X_hjälpa på plats',\n",
       " 'X_hjälpa riktiga jävla idioter som har valt att skaffa barn på plats',\n",
       " 'X_hjälpa skadade gäller alla som kan - förutom t.ex. poliser i tjänst med tydliga högre uppgifter , som att undvika att man får fler offer och skadade på plats',\n",
       " 'X_hjälpa tand- och allehanda rötor som varit på plats',\n",
       " 'X_hjälpa till att hålla lugnt på plats',\n",
       " 'X_hjälpa till när det behövs , men inte i sverige , utan på plats',\n",
       " 'X_hjälpa till om brott skulle ske på plats',\n",
       " 'X_hjälpafolk på plats',\n",
       " 'X_hjälpandet på plats',\n",
       " 'X_hjälparbetare likvidera individen på plats',\n",
       " 'X_hjälparbetare och läkare på plats',\n",
       " 'X_hjälparbetare och myndigheter på plats',\n",
       " 'X_hjälparbetare på plats',\n",
       " 'X_hjälparbetare som kan bli föräldrar åt flyktingbarnen på plats',\n",
       " 'X_hjälparbetare som är på plats',\n",
       " 'X_hjälparbetares lyxliv på plats',\n",
       " 'X_hjälparbetarna på plats',\n",
       " 'X_hjälparbetet på plats',\n",
       " 'X_hjälpare , hur tror du annars de fått tillträde att vara på plats',\n",
       " 'X_hjälpare kan ju vara att man är på plats',\n",
       " 'X_hjälpare och sedan ute i samhället sitta på plats',\n",
       " 'X_hjälpare på plats',\n",
       " 'X_hjälpare vilket har kunnat betyda att han redan var på plats',\n",
       " 'X_hjälpare även på plats',\n",
       " 'X_hjälpas med bistånd från olika hjälporganisationer på plats',\n",
       " 'X_hjälpas på plats',\n",
       " 'X_återvandr'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_terms = [\n",
    " 'A1_globalistisk',\n",
    " 'N1C_berikareX',\n",
    " 'N1C_förortsgängX',\n",
    " 'N1C_globalistX',\n",
    " 'N1C_kulturberikarX',\n",
    " 'N1C_återvandringsX',\n",
    " 'N1_berikare',\n",
    " 'N1_förortsgäng',\n",
    " 'N1_globalist',\n",
    " 'N1_kulturberikare',\n",
    " 'N1_återvandring',\n",
    " 'N2C_återvandrarX',\n",
    " 'N2_återvandrare',\n",
    " 'P1_ordning_och_reda_i_flyktingpolitiken',\n",
    " 'P1_självständig_utrikespolitik',\n",
    " 'V1_berika',\n",
    " 'V1_hjälpa_på_plats',\n",
    " 'V1_kulturberika',\n",
    " 'V1_återvandra',\n",
    " 'V2_hjälpa_X_på_plats'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = {\n",
    "    \"N1C_berikareX\": \"N1_berikare\",\n",
    "    \"N1C_förortsgängX\": \"N1_förortsgäng\",\n",
    "    \"N1C_globalistX\": \"N1_globalist\",\n",
    "    \"N1C_kulturberikarX\": \"N1_kulturberikare\",\n",
    "    \"N1C_återvandringsX\": \"N1_återvandring\",\n",
    "    \"N2C_återvandrarX\": \"N2_återvandrare\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1_globalistisk',\n",
       " 'N1_berikare',\n",
       " 'N1_förortsgäng',\n",
       " 'N1_globalist',\n",
       " 'N1_kulturberikare',\n",
       " 'N1_återvandring',\n",
       " 'N2_återvandrare',\n",
       " 'P1_ordning_och_reda_i_flyktingpolitiken',\n",
       " 'P1_självständig_utrikespolitik',\n",
       " 'V1_berika',\n",
       " 'V1_hjälpa_på_plats',\n",
       " 'V1_kulturberika',\n",
       " 'V1_återvandra',\n",
       " 'V2_hjälpa_X_på_plats']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict terms\n",
    "merge = True\n",
    "if merge:\n",
    "    selected_terms = [term for term in selected_terms if term not in merger]\n",
    "selected_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create files for vectors per term\n",
    "for directory in os.listdir(vec_root): # fb_nli etc.\n",
    "    os.mkdir(vpt_root / directory)\n",
    "    for x in selected_terms:\n",
    "        file = open(vpt_root / directory / f\"{x}.txt\", mode = \"x\")\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create files for contexts (words) per term\n",
    "for x in selected_terms:\n",
    "    file = open(xpt_root / f\"{x}.txt\", mode = \"x\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count \n",
    "total = 0\n",
    "for directory in os.listdir(vec_root):\n",
    "    for file in os.listdir(vec_root / directory):\n",
    "        with open(vec_root / directory / file) as f:\n",
    "            for line in f:\n",
    "                term = line.split(\"\\t\")[0]\n",
    "                \n",
    "                if merge:\n",
    "                    if term in merger:\n",
    "                        term = merger[term]\n",
    "                \n",
    "                if term in selected_terms:\n",
    "                    total += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sts_fbmodel_big_40epochs\n",
      "99.999 %\n",
      "fb_nli\n",
      "99.999 %%%%\n",
      "sentence-bert-swedish-cased\n",
      "99.999 %% %%\n",
      "sts_fbmodel\n",
      "99.999 % %\n"
     ]
    }
   ],
   "source": [
    "# build context per term - vectors (CPT)\n",
    "for directory in os.listdir(vec_root):\n",
    "    count = 0\n",
    "    print(directory)\n",
    "    for file in sorted(os.listdir(vec_root / directory)):\n",
    "        year = file.replace(\".txt\", \"\")\n",
    "        with open(vec_root / directory / file) as f: \n",
    "            for line in f:\n",
    "                term, vector = tuple(line.strip(\"\\n\").split(\"\\t\"))\n",
    "                #context = context.strip(\"\\n\")\n",
    "\n",
    "                if merge:\n",
    "                    if term in merger:\n",
    "                        term = merger[term]                \n",
    "                \n",
    "                if term not in selected_terms:\n",
    "                    continue\n",
    "                filename = f\"{term}.txt\"\n",
    "                \n",
    "                with open(vpt_root / directory / filename, mode=\"a\") as g:\n",
    "                    g.write(f\"{year}\\t{vector}\\n\")\n",
    "                print(round((count / total)*100, 3), \"%\", end=\"\\r\")\n",
    "                count += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.999 %%% %\n",
      "89267\n"
     ]
    }
   ],
   "source": [
    "# build context per term - words (XPT) \n",
    "count = 0\n",
    "for file in sorted(os.listdir(ctx_root)):\n",
    "    year = file.replace(\".txt\", \"\")\n",
    "    with open(ctx_root / file) as f: \n",
    "        for line in f:\n",
    "            terms, n_typ, context = tuple(line.strip(\"\\n\").split(\"\\t\"))\n",
    "            #context = context.strip(\"\\n\")\n",
    "            \n",
    "            for term in terms.split(\"; \"):\n",
    "\n",
    "                if merge:\n",
    "                    if term in merger:\n",
    "                        term = merger[term]                \n",
    "\n",
    "                if term not in selected_terms:\n",
    "                    continue\n",
    "\n",
    "                filename = f\"{term}.txt\"\n",
    "\n",
    "                with open(xpt_root / filename, mode=\"a\") as g:\n",
    "                    g.write(f\"{year}\\t{context}\\n\")\n",
    "                print(round((count / total)*100, 3), \"%\", end=\"\\r\")\n",
    "                count += 1\n",
    "print()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
