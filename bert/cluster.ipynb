{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(filepath):\n",
    "    data = dict()\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            dwt, vector = tuple(line.strip(\"\\n\").split(\"\\t\"))\n",
    "            vector = [float(v) for v in vector.split()]\n",
    "            if dwt in data:\n",
    "                data[dwt].append(vector)\n",
    "            else: \n",
    "                data[dwt] = [vector]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(filepath):\n",
    "    data = dict()\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            dwt, n_type, sentence = tuple(line.strip(\"\\n\").split(\"\\t\"))\n",
    "            if int(n_type) != 1:\n",
    "                for dwt in dwt.split(\"; \"):\n",
    "                    if dwt in data:\n",
    "                        data[dwt].append(sentence)\n",
    "                    else:\n",
    "                        data[dwt] = [sentence]\n",
    "                continue    \n",
    "            if dwt in data:\n",
    "                data[dwt].append(sentence)\n",
    "            else: \n",
    "                data[dwt] = [sentence]\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=1.5)\n",
    "#clustering_model = AgglomerativeClustering(n_clusters=None, metric=\"cosine\", distance_threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1,2,2].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cos(vectors, centroid):\n",
    "    return np.dot(vectors, centroid) / (np.linalg.norm(vectors, axis=1)*np.linalg.norm(centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_example(vectors, sentences, ):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(vectors_at, sentences_at, filename, cl_model, min_frq = 5):\n",
    "    \n",
    "    vectors_at = Path(vectors_at)\n",
    "    sentences_at = Path(sentences_at)\n",
    "    \n",
    "    data = get_vectors(vectors_at / filename)\n",
    "    sentences = get_sentences(sentences_at / filename)\n",
    "    \n",
    "#     for s in sentences[\"V1_kulturberika\"]:\n",
    "#         print(s[:30])\n",
    "    \n",
    "    for key in sorted(data.keys()):\n",
    "        assert len(data[key]) == len(sentences[key]), f\"Not the same number of sentences as vectors! {len(data[key])} vectors vs. {len(sentences[key])} sentences\"\n",
    "        \n",
    "        l = len(data[key])\n",
    "        \n",
    "        if l < 2:\n",
    "            print()\n",
    "            print(key.upper())\n",
    "            print(\"No. sentences\", l)\n",
    "            continue\n",
    "        \n",
    "        arr = np.array(data[key])\n",
    "        arr_norm = arr /  np.linalg.norm(arr, axis=1, keepdims=True)\n",
    "        cl_model.fit(arr_norm)\n",
    "        \n",
    "        label_counts = Counter(cl_model.labels_)\n",
    "        labels = dict()\n",
    "        \n",
    "        \n",
    "        for label, vector in zip(cl_model.labels_, arr):\n",
    "            if label in labels:\n",
    "                labels[label].append(vector)\n",
    "            else:\n",
    "                labels[label] = [vector]\n",
    "        \n",
    "        centroids = dict()\n",
    "        examples  = dict()\n",
    "        for label in labels.keys():\n",
    "            centroid = np.array(labels[label]).mean(axis=0)\n",
    "            centroids[label] = centroid\n",
    "            #print(centroid)\n",
    "            similarities = np_cos(data[key], centroid)\n",
    "            idx_max = np.argmax(similarities)\n",
    "            examples[label] = (sentences[key][idx_max], similarities[idx_max])\n",
    "        \n",
    "        print()\n",
    "        print(str(key).upper())\n",
    "        print(\"No. sentences\", l)\n",
    "        print(\"No. labels\", len(set(cl_model.labels_)))\n",
    "        \n",
    "        for label in labels:\n",
    "            n = label_counts[label]\n",
    "            if n >= min_frq:\n",
    "                print(f\"LABEL_{label}, (n = {n})\")\n",
    "                ex, v = examples[label]\n",
    "                print(f\"({v:.2f}) {ex}\")\n",
    "                \n",
    "#         for label in sorted(centroids.keys()):\n",
    "#             print(label)\n",
    "#             print(centroids[label].tolist())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_path = \"/home/max/Corpora/flashback-pol-time/yearly/contexts/vectors/sts_fbmodel\"\n",
    "snt_path = \"/home/max/Corpora/flashback-pol-time/yearly/contexts/files\"\n",
    "filename = \"2015.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A1_GLOBALISTISK\n",
      "No. sentences 171\n",
      "No. labels 15\n",
      "LABEL_0, (n = 22)\n",
      "(0.76) det är ett multikulturellt företag med en öppen anti-rasistisk / globalistisk agenda .\n",
      "LABEL_2, (n = 25)\n",
      "(0.77) han hör ju till de globalistiska grupperingar inom bl.a. media som vill destabilisera europa med massinvandring , globalism och krigshetsande anti-rysk propaganda .\n",
      "\n",
      "N1C_BERIKAREX\n",
      "No. sentences 9\n",
      "No. labels 1\n",
      "\n",
      "N1C_GLOBALISTX\n",
      "No. sentences 228\n",
      "No. labels 18\n",
      "LABEL_3, (n = 23)\n",
      "(0.80) ja , men det beror väl närmast på att vänstern i sverige ( v+mp ) valde att kort efter murens fall dra mer åt extremvänsterhåll med folkförnekelse , genustrams och fri invandring för att motivera sin existens , med det enda resultatet att de numera har gjort sig till globalistkapitalets stjärtgossar .\n",
      "LABEL_1, (n = 20)\n",
      "(0.76) globalistförespråkare , skulle jag kalla alla vänsterradikala , liberaldårar och nyttiga idioter som destabiliserar sina samhällen i globalismens namn .\n",
      "LABEL_4, (n = 21)\n",
      "(0.79) det patetiska , folkförrädande globalistsvin som klämt ur sig ovan text bjuder på nya nivåer av humor i kriget för folkutbytets snara genomförande .\n",
      "LABEL_0, (n = 22)\n",
      "(0.78) de nöjer sig inte med annat än total ödeläggelse av svensk natur och kultur , inte konstigt då de är finansierade av icke-svenskar för att tjäna globalistkapitalistiska syften , plan b .\n",
      "\n",
      "N1C_KULTURBERIKARX\n",
      "No. sentences 2\n",
      "No. labels 1\n",
      "\n",
      "N1C_ÅTERVANDRINGSX\n",
      "No. sentences 67\n",
      "No. labels 5\n",
      "LABEL_0, (n = 20)\n",
      "(0.83) vidare är återvandringsbidrag fullt lagligt .\n",
      "\n",
      "N1_BERIKARE\n",
      "No. sentences 216\n",
      "No. labels 18\n",
      "LABEL_1, (n = 20)\n",
      "(0.76) du kommer nog att chockas när du inser vilken kvinnosyn dina kära berikare har .\n",
      "\n",
      "N1_FÖRORTSGÄNG\n",
      "No. sentences 17\n",
      "No. labels 1\n",
      "\n",
      "N1_GLOBALIST\n",
      "No. sentences 582\n",
      "No. labels 50\n",
      "LABEL_2, (n = 23)\n",
      "(0.77) då kanske det är något fel på den globaliserade världen och istället bör denna galna idé skrotas till förmån för nationellt inriktade idéer som satsar på bilaterala affärer med omvärlden istället för att globalister skall inför slavlöner för alla .\n",
      "LABEL_7, (n = 29)\n",
      "(0.82) det sägs att djävulen blandar sanningar med sina lögner för att göra dem mer effektiva , och är något sant som ryssen säger så är det att väst / europa är degenererat - åtminstone vad våra makthavare och maktorgan angår - mähän , fjollor , mångkulturalister , egalitärdogmatiska globalister och penningdyrkare .\n",
      "\n",
      "N1_KULTURBERIKARE\n",
      "No. sentences 143\n",
      "No. labels 10\n",
      "LABEL_1, (n = 22)\n",
      "(0.78) ju fler kulturberikare bland fin-folket , desto bättre eftersom det finns säkert väldigt stort motstånd mot massinvandring att finna där bland folk som bara behöver få uppleva det lite så att de inser vart fan allt är påväg .\n",
      "LABEL_2, (n = 20)\n",
      "(0.82) snart avrättar väl regeringen alla svenska pensionärer så att fler invandrare ska ha någonstans att bo.detta land är så obegripligt sinnessjukt.man blir så jävla less på att kulturberikarna , kebabteknikerna och alla spökhucklen ska få åka på en räkmacka medan svensken ständigt pissas på.men så länge idioter röstar med arslet får vi finna oss i att sverige sakta men säkert trasas sönder .\n",
      "\n",
      "N1_ÅTERVANDRING\n",
      "No. sentences 81\n",
      "No. labels 6\n",
      "LABEL_0, (n = 26)\n",
      "(0.83) sen finns det säkert en mycket stor andel utlänningar som vill återvända till sina hemländer , sd:s projekt med återvandring skulle ju då bli intressant .\n",
      "\n",
      "N2C_ÅTERVANDRARX\n",
      "No. sentences 1\n",
      "\n",
      "N2_ÅTERVANDRARE\n",
      "No. sentences 2\n",
      "No. labels 1\n",
      "\n",
      "P1_ORDNING_OCH_REDA_I_FLYKTINGPOLITIKEN\n",
      "No. sentences 4\n",
      "No. labels 1\n",
      "\n",
      "P1_SJÄLVSTÄNDIG_UTRIKESPOLITIK\n",
      "No. sentences 6\n",
      "No. labels 1\n",
      "\n",
      "V1_BERIKA\n",
      "No. sentences 1212\n",
      "No. labels 95\n",
      "LABEL_38, (n = 31)\n",
      "(0.86) jag kan inte förstå hur ni menar att detta skulle berika vårt samhälle .\n",
      "LABEL_3, (n = 25)\n",
      "(0.83) samtidigt talar man vitt och brett om att flyktingarna ska berika vår kultur och rädda vår välfärd .\n",
      "LABEL_24, (n = 29)\n",
      "(0.82) men om vi köper deras världsbild om mångfald uppstår paradoxen i deras beteende - vi ska alltså berikas av etnisk mångfald , och detta ska vara positivt , men samtidigt ska vi inte få veta bakgrunden om en icke-vit persons etnicitet om denne lever bland vita .\n",
      "LABEL_21, (n = 32)\n",
      "(0.86) sen finns det såklart argumenten att mångkultur är berikande för befolkningen och att kulturutbytet gynnar företagandet och framväxandet av nya idéer som kommer påverka sveriges ekonomi positivt och öka konkurrenskraften .\n",
      "LABEL_49, (n = 23)\n",
      "(0.85) då inget är sant eller snarare det sanna är det man bestämmer sig för , uppstår det vi kallar agenda med påstådd fara för islamofobi , invandringen är egentligen liten och bara berikar , kritiker är per automatik fascister , sverige har varit en brutal kolonialmakt , endast svenskar kan vara rasister , det råder strukturell rasism osv .\n",
      "LABEL_15, (n = 20)\n",
      "(0.80) när det kommer till kritan ( som det gör i verkliga livet ) vill \" alla åt alla \" helst berika sig själva men på andras bekostnad .\n",
      "LABEL_6, (n = 23)\n",
      "(0.79) \" berika \" ?\n",
      "LABEL_1, (n = 20)\n",
      "(0.78) många kommuner som av rädsla och inskränkthet nekat flyktingar att komma in i gemenskapen kommer att inse hur berikande det är med inflöde av globala ideer och innovationer .\n",
      "LABEL_45, (n = 23)\n",
      "(0.82) självklart ljuger de politiska miljonärer som \" är staten \" för alla slavar i hopp om att girigt berika sig själva ännu mer .\n",
      "LABEL_56, (n = 22)\n",
      "(0.81) flera är redan i norra europa ... de ska berika sverige ... vill inte stanna kvar i danmark ( halverad bidrag , ingen sans till livstids försöjning och gratis hus / lägenhet ) .\n",
      "LABEL_10, (n = 22)\n",
      "(0.82) är det bra för integrationen i samhället att etnisk homogena områden berikas på detta sätt ?\n",
      "LABEL_22, (n = 21)\n",
      "(0.81) varje dag blir nya svenskar \" berikade \" och går då över till sd .\n",
      "\n",
      "V1_HJÄLPA_PÅ_PLATS\n",
      "No. sentences 278\n",
      "No. labels 16\n",
      "LABEL_4, (n = 29)\n",
      "(0.85) istället bör vi hjälpa på plats och se till att alla länder får förbättrade institutioner då den politik vi för i dagsläget är ohållbar .\n",
      "LABEL_7, (n = 25)\n",
      "(0.94) det är bättre att hjälpa på plats .\n",
      "LABEL_0, (n = 29)\n",
      "(0.78) hade sd gått ut hårdare hade man dels belyst hur akuta migrationsproblem är i sverige samtidigt som man lämnar fritt spelrum för ett borgerligt alternativ att säga \" så långt vill inte vi gå men vi bör minska invandringen och hjälpa på plats istället ! \" .\n",
      "LABEL_3, (n = 24)\n",
      "(0.84) ska vi verkligen låta tiotusentals dö för att det för svårt att hjälpa på plats ?\n",
      "LABEL_1, (n = 31)\n",
      "(0.86) att hjälpa på plats istället för i sverige behöver inte vara ett främlingsfientligt utspel , men när sd använder det argumentet så framstår det på det viset för att de i grund och botten inte uppfattas som välmenande .\n",
      "LABEL_9, (n = 22)\n",
      "(0.89) på plats förstår varje tänkande individ att det handlar om att hjälpa på plats om det går .\n",
      "\n",
      "V1_KULTURBERIKA\n",
      "No. sentences 126\n",
      "No. labels 10\n",
      "LABEL_2, (n = 24)\n",
      "(0.79) det ska man naturligtvis inte göra då ännu färre kommer att rösta på sverigedemokraterna i stockholm om sd försöker göra stockholm ännu mer kulturberikat .\n",
      "LABEL_0, (n = 27)\n",
      "(0.77) de tycker väl att det är det finasre man kan bli dvs kulturberikad ..\n",
      "\n",
      "V1_ÅTERVANDRA\n",
      "No. sentences 28\n",
      "No. labels 2\n",
      "\n",
      "V2_HJÄLPA_X_PÅ_PLATS\n",
      "No. sentences 464\n",
      "No. labels 27\n",
      "LABEL_11, (n = 24)\n",
      "(0.90) sd säger sig vilja hjälpa folk på plats .\n",
      "LABEL_24, (n = 22)\n",
      "(0.91) och vi borde försöka hjälpa till så gott vi kan på plats .\n",
      "LABEL_9, (n = 32)\n",
      "(0.87) och när det gäller att hjälpa människor i nöd så gör vi det på ett ineffektivt och dyrt sätt som få har någon egentlig glädje av , vi skulle kunna hjälpa så många fler om vi slutar envisas med att alla ska hjälpas på plats i sverige .\n",
      "LABEL_4, (n = 30)\n",
      "(0.86) nu vill han även hjälpa folk på plats .\n",
      "LABEL_15, (n = 20)\n",
      "(0.87) och \" hjälpa på plats \" jag hade gärna sett att han hade lite mer statistik att presentera , tex hur mycket det kostar att ta emot flyktingar här varje år samt hur många fler de pengarna skulle kunna hjälpa syrierna på plats så det blev lite mer konkret .\n",
      "LABEL_1, (n = 27)\n",
      "(0.88) dels kan vi hjälpa fler människor på plats .\n",
      "LABEL_19, (n = 22)\n",
      "(0.82) och när det gäller att hjälpa människor i nöd så gör vi det på ett ineffektivt och dyrt sätt som få har någon egentlig glädje av , vi skulle kunna hjälpa så många fler om vi slutar envisas med att alla ska hjälpas på plats i sverige .\n",
      "LABEL_2, (n = 27)\n",
      "(0.85) att hjälpa människor på plats i närområdet fråntar oss dock inte vårt ansvar för att hjälpa dem som tagit sig till sverige .\n",
      "LABEL_6, (n = 22)\n",
      "(0.85) vi kan göra som nu och låta dom som har råd och ork låta sig smugglas hit utan att någon bryr sig om dom har asylskäl eller ej , eller vi kan hjälpa så många som möjligt på plats genom fn och hjälporganisationerna .\n",
      "\n",
      "X_BERIKA\n",
      "No. sentences 49\n",
      "No. labels 5\n",
      "\n",
      "X_GLOBALIST\n",
      "No. sentences 66\n",
      "No. labels 7\n",
      "\n",
      "X_HJÄLPARBETARE OCH MYNDIGHETER PÅ PLATS\n",
      "No. sentences 1\n",
      "\n",
      "X_HJÄLPARBETARE PÅ PLATS\n",
      "No. sentences 1\n",
      "\n",
      "X_HJÄLPARE OCH SEDAN UTE I SAMHÄLLET SITTA PÅ PLATS\n",
      "No. sentences 1\n",
      "\n",
      "X_HJÄLPARE PÅ PLATS\n",
      "No. sentences 1\n",
      "\n",
      "X_HJÄLPAS PÅ PLATS\n",
      "No. sentences 17\n",
      "No. labels 2\n",
      "\n",
      "X_ÅTERVANDR\n",
      "No. sentences 3\n",
      "No. labels 1\n"
     ]
    }
   ],
   "source": [
    "get_clusters(\n",
    "    vectors_at = vec_path, \n",
    "    sentences_at = snt_path, \n",
    "    filename = filename, \n",
    "    cl_model = clustering_model,\n",
    "    min_frq = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
